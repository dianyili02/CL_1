#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
test0902.py â€” éšæœºåœ°å›¾è¯„æµ‹ï¼ˆå¼ºåŒ–ç‰ˆï¼‰
ç‰¹æ€§æ±‡æ€»ï¼š
1) ä¸¥æ ¼æˆåŠŸåˆ¤å®šï¼šåªæœ‰çœŸæ­£åˆ°è¾¾æ‰€æœ‰ç›®æ ‡æ‰è®° success
2) è§‚æµ‹å½’ä¸€åŒ–ï¼šè‡ªåŠ¨æŠŠè¾“å…¥å¼ é‡ç¼©æ”¾åˆ° [0,1]
3) é¢„æµ‹è®©è¡Œé˜²æŠ–ï¼šåœ¨ step ä¹‹å‰é¢„æµ‹å¯¹å‘å¯¹å†²ï¼Œæå‰è®©åŠæ•°ä»£ç† idle
4) æ¸è¿›å¼ A* è§£å›°ï¼šç›®æ ‡ä»£ç†è¿ç»­å¡ä½å³çŸ­æœŸäº¤ç»™ A*ï¼Œæœ‰è¿›å±•é€æ­¥å½’è¿˜
5) æ˜“â†’éš¾åŠ¨æ€è§£é”ï¼šå…ˆåœ¨æ˜“å›¾ä¸Šè·‘åˆ° SRâ‰¥0.6 å†è‡ªåŠ¨æ”¾å¤§æœç´¢ç©ºé—´
6) åŠ¨ä½œé¡ºåºé”å®šï¼šå¼ºåˆ¶æŒ‰è®­ç»ƒæ—¶é¡ºåº ['idle','up','down','left','right'] ä¸‹å‘åˆ°ç¯å¢ƒ
7) å…¼å®¹ä¸¤ç§ step è¿”å›æ ¼å¼ï¼š(obs,reward,terminated,truncated,info) æˆ– (obs,reward,dones,info)
8) å‚æ•°ï¼š--assist-astar, --max-steps-mult, --easy-first, --per-episode-seed

ç”¨æ³•ç¤ºä¾‹ï¼ˆPowerShell å•è¡Œï¼‰ï¼š
python .\test0902.py --weights .\models\best_model.pt --episodes 100 --device cpu --out-dir .\eval_runs --per-episode-seed --assist-astar --max-steps-mult 4 --easy-first
"""

import os, sys, math, random, argparse, json, csv, inspect, time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional

import numpy as np
import torch

# ====== å·¥ç¨‹æ¨¡å— ======
project_root_guess = os.path.abspath(".")
if project_root_guess not in sys.path:
    sys.path.insert(0, project_root_guess)

from g2rl.environment import G2RLEnv
from g2rl.network import CRNNModel
from g2rl.agent import DDQNAgent

try:
    from pogema import AStarAgent
except Exception:
    AStarAgent = None  # æœªå®‰è£…æ—¶ï¼Œassist/self-rescue ä¼šè¢«è·³è¿‡

# ====== é‡‡æ ·ç©ºé—´ ======
EASY_SIZES    = [32, 64]
EASY_AGENTS   = [2, 4]
EASY_DENS     = [0.1, 0.3]

FULL_SIZES    = [32, 64, 96, 128]
FULL_AGENTS   = [2, 4, 8, 16]
FULL_DENS     = [0.1, 0.3, 0.5, 0.7]

# ====== Utils ======
def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

def ensure_out_dir(out_dir: str) -> Path:
    p = Path(out_dir)
    p.mkdir(parents=True, exist_ok=True)
    return p

def _find_array(obj):
    try:
        import torch as _t  # noqa
        is_tensor = True
    except Exception:
        is_tensor = False
    if isinstance(obj, np.ndarray):
        return obj
    if is_tensor and hasattr(obj, "detach") and hasattr(obj, "cpu") and hasattr(obj, "numpy"):
        try:
            return obj.detach().cpu().numpy()
        except Exception:
            pass
    if isinstance(obj, (list, tuple)):
        for v in obj:
            arr = _find_array(v)
            if arr is not None:
                return arr
        return None
    if isinstance(obj, dict):
        preferred = ("view_cache","obs","observation","view","state","tensor","grid","image","local_obs","global_obs")
        for k in preferred:
            if k in obj:
                arr = _find_array(obj[k])
                if arr is not None:
                    return arr
        for v in obj.values():
            arr = _find_array(v)
            if arr is not None:
                return arr
        return None
    try:
        arr = np.array(obj)
        if arr.ndim > 0:
            return arr
    except Exception:
        pass
    return None

def _to_CDHW(arr):
    if not isinstance(arr, np.ndarray):
        arr = np.array(arr)
    if arr.ndim == 5:
        # [N,C,D,H,W] or [N,D,H,W,C]
        if arr.shape[1] in (1,2,3,4,5,8,11,16):
            arr = arr[0]
        else:
            arr = np.transpose(arr, (0,4,1,2,3))[0]
    elif arr.ndim == 4:
        # [C,D,H,W] or [D,H,W,C]
        if arr.shape[0] in (1,2,3,4,5,8,11,16):
            pass
        elif arr.shape[-1] in (1,2,3,4,5,8,11,16):
            arr = np.transpose(arr, (3,0,1,2))
        else:
            arr = np.transpose(arr, (3,0,1,2))
    elif arr.ndim == 3:
        arr = arr[None, ...]
    elif arr.ndim == 2:
        arr = arr[None, None, ...]
    else:
        raise ValueError(f"æ— æ³•å½’ä¸€åˆ° [C,D,H,W]ï¼šshape={arr.shape}")
    return arr

def obs_to_tensor(s, device, expected_c: int = 11):
    arr = _find_array(s)
    if arr is None:
        raise KeyError("æ— æ³•ä»è§‚æµ‹ä¸­æå–è¾“å…¥å¼ é‡ã€‚è¯·ç¡®ä¿è§‚æµ‹åŒ…å«å¯è½¬æ•°ç»„å­—æ®µï¼Œå¦‚ view_cache/obs ç­‰ã€‚")
    arr = _to_CDHW(arr)  # [C,D,H,W]
    C, D, H, W = arr.shape
    if C == expected_c:
        arr_fixed = arr
    elif C == 1 and expected_c > 1:
        arr_fixed = np.repeat(arr, expected_c, axis=0)
    elif C < expected_c:
        pad = np.zeros((expected_c - C, D, H, W), dtype=arr.dtype)
        arr_fixed = np.concatenate([arr, pad], axis=0)
    else:
        arr_fixed = arr[:expected_c]
    x = torch.tensor(arr_fixed[None, ...], dtype=torch.float32, device=device)  # [1,C,D,H,W]

    # === å½’ä¸€åŒ–åˆ° [0,1]ï¼ˆé¿å…è®­ç»ƒ/è¯„æµ‹å°ºåº¦ä¸ä¸€è‡´ï¼‰ ===
    x_min, x_max = float(x.min().item()), float(x.max().item())
    if (x_min < 0.0) or (x_max > 1.0):
        denom = (x_max - x_min) if (x_max - x_min) > 1e-6 else 1.0
        x = (x - x_min) / denom

    return x

def count_collisions(positions_before: List[Tuple[int, int]], positions_after: List[Tuple[int, int]]) -> int:
    c = 0
    uniq = set(positions_after)
    if len(uniq) < len(positions_after):
        c += (len(positions_after) - len(uniq))
    moved = [(positions_before[i], positions_after[i]) for i in range(len(positions_after))]
    for i in range(len(moved)):
        for j in range(i + 1, len(moved)):
            if moved[i][0] == moved[j][1] and moved[i][1] == moved[j][0]:
                c += 1
    return c

def reached_goal(obs, info) -> bool:
    # ç¯å¢ƒæ˜¾å¼ success
    if isinstance(info, dict) and (info.get("success") or info.get("finished") or info.get("all_done")):
        return True
    # å…¨éƒ¨åˆ°è¾¾
    try:
        for i in range(len(obs)):
            if tuple(map(int, obs[i]["global_xy"])) != tuple(map(int, obs[i]["global_target_xy"])):
                return False
        return True
    except Exception:
        return False

def build_env(size: int, num_agents: int, density: float, seed: Optional[int], max_steps_mult: int = 4) -> G2RLEnv:
    """åªä¼  __init__ æ”¯æŒçš„é”®ï¼Œå¹¶å°½é‡è¦†ç›–å†…éƒ¨ max_episode_stepsã€‚"""
    ctor = dict(
        size=int(size),
        num_agents=int(num_agents),
        density=float(density),
        seed=(int(seed) if seed is not None else 42),
        obs_radius=7,
        on_target="nothing",
        collission_system="soft",
        max_episode_steps=int(max_steps_mult * int(size)),
    )
    sig = inspect.signature(G2RLEnv.__init__)
    allowed = {p.name for p in sig.parameters.values()
               if p.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD, inspect.Parameter.KEYWORD_ONLY)}
    allowed.discard("self")
    ctor = {k: v for k, v in ctor.items() if k in allowed}
    env = G2RLEnv(**ctor)
    try:
        if hasattr(env, "grid_config"):
            env.grid_config.max_episode_steps = int(max_steps_mult * int(size))
    except Exception:
        pass
    return env

def choose_action_with_compat(agent, obs_i, device_t):
    """å…¼å®¹å¤šç§ act ç­¾åï¼›ä¼ ä¸è¿›åŸå§‹è§‚æµ‹å°±ä¼  tensorï¼›å†ä¸è¡Œç›´æ¥è´ªå¿ƒã€‚"""
    if hasattr(agent, "act"):
        try:
            return int(agent.act(obs_i))
        except TypeError:
            try:
                return int(agent.act(obs_i, epsilon=0.0))
            except Exception:
                pass
        except Exception:
            pass
    x = obs_to_tensor(obs_i, device_t, expected_c=11)
    if hasattr(agent, "act"):
        try:
            return int(agent.act(x))
        except TypeError:
            try:
                return int(agent.act(x, epsilon=0.0))
            except Exception:
                pass
        except Exception:
            pass
    with torch.no_grad():
        q = agent.model(x)
        return int(torch.argmax(q, dim=1).item())

# === å¯¹å‘å¯¹å†²é¢„æµ‹ ===
DELTA_BY_NAME = {
    'idle': (0,0),
    'up':   (-1,0),
    'down': (1,0),
    'left': (0,-1),
    'right':(0,1),
}
def will_back_forth(prev_pos, planned_pos):
    pairs = [(prev_pos[i], planned_pos[i]) for i in range(len(planned_pos))]
    S = set(pairs)
    for u,v in pairs:
        if u != v and (v,u) in S:
            return True
    return False

def apply_delta(pos, action_name):
    dx, dy = DELTA_BY_NAME.get(action_name, (0,0))
    return (pos[0]+dx, pos[1]+dy)

def manhattan(p, q):
    return abs(p[0]-q[0]) + abs(p[1]-q[1])

# ====== ä¸»è¯„æµ‹ ======
def evaluate_random(
    weights_path: str,
    episodes: int,
    device: str,
    out_dir: str,
    per_episode_seed: bool,
    assist_astar: bool,
    max_steps_mult: int,
    easy_first: bool,
):
    set_seed(42)
    device_t = "cuda" if (device=="cuda" and torch.cuda.is_available()) else "cpu"

    # é¢„çƒ­ env & åŠ¨ä½œæ•°
    warm_env = build_env(size=32, num_agents=2, density=0.1, seed=123, max_steps_mult=max_steps_mult)
    try:
        action_space = warm_env.get_action_space()
        if hasattr(action_space, "n"):
            n_actions = int(action_space.n)
        elif isinstance(action_space, (list, tuple)):
            n_actions = len(action_space)
        elif isinstance(action_space, int):
            n_actions = action_space
        else:
            n_actions = 5
    except Exception:
        n_actions = 5

    model = CRNNModel(num_actions=n_actions, in_channels=11).to(device_t)

    # åŠ è½½ agent / æ¨¡å‹
    agent = None; loaded = False
    if hasattr(DDQNAgent, "load") and callable(getattr(DDQNAgent, "load")):
        try:
            agent = DDQNAgent.load(weights_path, device=device_t)
            agent.model.to(device_t)
            loaded = True
            print(f"âœ… ä½¿ç”¨ DDQNAgent.load() åŠ è½½æƒé‡ï¼š{weights_path}")
        except Exception as e:
            print(f"âš ï¸ DDQNAgent.load() å¤±è´¥ï¼Œå°†ä½¿ç”¨ torch.load: {e}")

    if not loaded:
        sd = torch.load(weights_path, map_location=device_t)
        if isinstance(sd, dict) and "state_dict" in sd:
            model.load_state_dict(sd["state_dict"])
        elif isinstance(sd, dict) and "model_state_dict" in sd:
            model.load_state_dict(sd["model_state_dict"])
        else:
            model.load_state_dict(sd)
        agent = DDQNAgent(model, model, list(range(n_actions)), lr=1e-3, device=device_t)  # ä»…ç”¨äº act
        agent.model = model
        print(f"âœ… ä½¿ç”¨ torch.load() åŠ è½½æ¨¡å‹å‚æ•°ï¼š{weights_path}")

    # è¯„æµ‹å¿…é¡»çº¯è´ªå¿ƒ
    if hasattr(agent, "set_epsilon"): agent.set_epsilon(0.0)
    if hasattr(agent, "epsilon"): agent.epsilon = 0.0
    model.eval()
    torch.set_grad_enabled(False)

    # è¾“å‡ºç›®å½•
    out_root = ensure_out_dir(out_dir)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_path = out_root / f"eval_{ts}"
    run_path.mkdir(parents=True, exist_ok=True)
    csv_path  = run_path / "episodes.csv"
    json_path = run_path / "summary.json"

    # å†™ CSV å¤´
    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow([
            "episode","size","num_agents","density",
            "success","steps","collisions_this_run","episode_seed",
            "termination_reason","stuck_steps_target"
        ])

    # åŠ¨æ€æ˜“â†’éš¾
    use_hard = False if easy_first else True
    win = []  # æœ€è¿‘çª—å£ success
    WIN_SIZE = 50
    UNLOCK_SR = 0.6

    def pick_cfg():
        if use_hard:
            return (int(np.random.choice(FULL_SIZES)),
                    int(np.random.choice(FULL_AGENTS)),
                    float(np.random.choice(FULL_DENS)))
        else:
            return (int(np.random.choice(EASY_SIZES)),
                    int(np.random.choice(EASY_AGENTS)),
                    float(np.random.choice(EASY_DENS)))

    # ç»Ÿè®¡
    sr_list = []; steps_list = []
    total_collisions = 0; total_steps = 0

    for ep in range(1, episodes+1):
        if per_episode_seed:
            epi_seed = int(np.random.randint(1_000_000_000))
            np.random.seed(epi_seed); random.seed(epi_seed); torch.manual_seed(epi_seed)
            if torch.cuda.is_available(): torch.cuda.manual_seed_all(epi_seed)
        else:
            epi_seed = None

        size, nag, den = pick_cfg()
        env = build_env(size=size, num_agents=nag, density=den, seed=epi_seed, max_steps_mult=max_steps_mult)

        # åŠ¨ä½œé¡ºåºé”å®šï¼ˆå¼ºåˆ¶æ˜ å°„ä¸ºè®­ç»ƒé¡ºåºï¼‰
        EXPECTED = ['idle','up','down','left','right']
        remap = None
        env_actions = getattr(env, "actions", None)
        if isinstance(env_actions, list) and env_actions != EXPECTED:
            idx = {name:i for i,name in enumerate(env_actions)}
            if all(n in idx for n in EXPECTED):
                remap = [idx[n] for n in EXPECTED]

        try:
            reset_ret = env.reset()
            if isinstance(reset_ret, tuple) and len(reset_ret) >= 1:
                obs, info = reset_ret[0], (reset_ret[1] if len(reset_ret) > 1 else {})
            else:
                obs, info = reset_ret, {}
        except Exception:
            obs, info = env.reset(), {}

        if ep == 1:
            print("Eval action list:", getattr(env, "actions", None))
            try:
                x0 = obs_to_tensor(obs[0], device_t, expected_c=11)
                print("x0.shape/min/max:", tuple(x0.shape), float(x0.min().item()), float(x0.max().item()))
            except Exception as e:
                print("é¢„å¤„ç†æ¢é’ˆå¤±è´¥ï¼š", e)

        num_agents = getattr(env, "num_agents", len(obs))
        teammates = []
        target_idx = 0
        for i in range(num_agents):
            if assist_astar and (i != target_idx) and (AStarAgent is not None):
                try:
                    teammates.append(AStarAgent())
                except Exception:
                    teammates.append(None)
            else:
                teammates.append(None)

        def get_positions(o: List[dict]) -> List[Tuple[int, int]]:
            pos = []
            for i in range(len(o)):
                try:
                    pos.append(tuple(map(int, o[i]["global_xy"])))
                except Exception:
                    pos.append((-10**9, -10**9))
            return pos

        prev_pos = get_positions(obs)
        last_pos = prev_pos[:]
        step = 0
        run_collisions = 0
        stuck_counter = [0]*num_agents
        stuck_steps_target = 0
        termination_reason = "other"

        # æ¸è¿›å¼ A* æ¥ç®¡
        K_STUCK = 3
        ASSIST_WINDOW = 10
        assist_left = 0
        last_goal_dist = None

        with torch.no_grad():
            while True:
                actions = []
                # ç­–ç•¥/é˜Ÿå‹ç”ŸæˆåŠ¨ä½œ
                for i in range(num_agents):
                    if teammates[i] is not None:
                        try:
                            a = int(teammates[i].act(obs[i]))
                        except Exception:
                            a = 0
                        actions.append(a)
                        continue
                    a = choose_action_with_compat(agent, obs[i], device_t)
                    actions.append(int(a))

                # åŠ¨ä½œé¡ºåºæ˜ å°„åˆ°ç¯å¢ƒç´¢å¼•
                if remap is not None:
                    # actions é‡Œä¿å­˜çš„æ˜¯ EXPECTED çš„ç´¢å¼•ï¼ˆ0..4ï¼‰
                    actions = [ remap[a] if (0 <= a < len(remap)) else 0 for a in actions ]

                # === é¢„æµ‹å¯¹å‘å¯¹å†²ï¼šåœ¨ step ä¹‹å‰è®©è¡Œ ===
                planned = []
                if isinstance(env_actions, list) and len(env_actions) > 0:
                    for i,a in enumerate(actions):
                        name = env_actions[a] if (0 <= a < len(env_actions)) else 'idle'
                        planned.append(apply_delta(prev_pos[i], name))
                    if will_back_forth(prev_pos, planned):
                        for i in range(0, num_agents, 2):
                            actions[i] = 0  # idle

                # === æ¸è¿›å¼ A* è§£å›°ï¼šå¡ä½å³æ¥ç®¡ï¼Œè¿›å±•åˆ™é€æ­¥å½’è¿˜ ===
                now_goal = tuple(map(int, obs[target_idx]['global_target_xy']))
                cur_pos  = tuple(map(int, prev_pos[target_idx]))
                dist_t   = manhattan(cur_pos, now_goal)
                if last_goal_dist is None:
                    last_goal_dist = dist_t

                if prev_pos[target_idx] == last_pos[target_idx]:
                    stuck_counter[target_idx] += 1
                else:
                    stuck_counter[target_idx] = 0
                stuck_steps_target += int(prev_pos[target_idx] == last_pos[target_idx])

                if (stuck_counter[target_idx] >= K_STUCK) and (AStarAgent is not None):
                    assist_left = ASSIST_WINDOW
                    stuck_counter[target_idx] = 0

                if assist_left > 0 and AStarAgent is not None:
                    try:
                        a_astar = int(AStarAgent().act(obs[target_idx]))
                        actions[target_idx] = a_astar if (remap is None) else (remap[a_astar] if 0 <= a_astar < len(remap) else 0)
                        assist_left -= 1
                        # è‹¥é¢„è®¡èƒ½æ‹‰è¿‘ç›®æ ‡è·ç¦»ï¼ˆç”¨ planned çš„ç›®æ ‡ä»£ç†ï¼‰
                        if isinstance(env_actions, list) and len(env_actions) > 0:
                            name_t = env_actions[actions[target_idx]] if 0 <= actions[target_idx] < len(env_actions) else 'idle'
                            next_pos_t = apply_delta(cur_pos, name_t)
                            if manhattan(next_pos_t, now_goal) < dist_t:
                                assist_left = max(assist_left-2, 0)
                    except Exception:
                        pass
                last_goal_dist = dist_t

                # === step ===
                ret = env.step(actions)
                if isinstance(ret, (list, tuple)) and len(ret) == 5:
                    next_obs, rewards, terminated, truncated, info = ret
                    dones_like = np.array(terminated, dtype=bool) | np.array(truncated, dtype=bool)
                    done_all = bool(np.all(dones_like))
                else:
                    next_obs, rewards, dones, info = ret
                    if isinstance(dones, (list, tuple, np.ndarray)):
                        done_all = all(bool(x) for x in dones)
                    elif isinstance(dones, dict) and "all_done" in dones:
                        done_all = bool(dones["all_done"])
                    else:
                        done_all = False

                now_pos = get_positions(next_obs)

                c = count_collisions(prev_pos, now_pos)
                run_collisions += c
                total_collisions += c
                total_steps += 1
                last_pos = prev_pos[:]
                prev_pos = now_pos

                step += 1
                obs = next_obs

                max_steps = getattr(env, "max_episode_steps", None)
                if max_steps is None and hasattr(env, "grid_config") and hasattr(env.grid_config, "max_episode_steps"):
                    max_steps = env.grid_config.max_episode_steps
                if max_steps is None:
                    max_steps = int(max_steps_mult * size)

                # === ä¸¥æ ¼æˆåŠŸ/æ­¥æ•°ç»ˆæ­¢ ===
                if reached_goal(obs, info):
                    termination_reason = "success"
                    break
                if step >= max_steps:
                    termination_reason = "max_steps"
                    break

        success = 1 if reached_goal(obs, info) else 0
        sr_list.append(success); steps_list.append(step)

        # åŠ¨æ€æ˜“->éš¾è§£é”
        if easy_first:
            win.append(success)
            if len(win) > WIN_SIZE:
                win.pop(0)
            if (not use_hard) and (len(win) == WIN_SIZE) and (sum(win)/WIN_SIZE >= UNLOCK_SR):
                use_hard = True
                print(f"ğŸ”“ å·²è§£é”éš¾å›¾ï¼šæœ€è¿‘{WIN_SIZE}é›† SR={sum(win)/WIN_SIZE:.2f}")

        # å†™å…¥ä¸€è¡Œ
        with open(csv_path, "a", newline="", encoding="utf-8") as f:
            w = csv.writer(f)
            w.writerow([
                ep, size, nag, f"{den:.6f}",
                success, step, run_collisions, (epi_seed or ""),
                termination_reason, stuck_steps_target
            ])

        print(f"[Episode {ep:04d}] Map(size={size}, agents={nag}, dens={den:.3f}) | "
              f"Success={'âœ…' if success else 'âŒ'} | Steps={step} | Collisions={run_collisions} | "
              f"Term={termination_reason} | StuckT={stuck_steps_target}")

    # æ±‡æ€»
    success_rate = float(np.mean(sr_list)) if len(sr_list) else 0.0
    avg_steps = float(np.mean(steps_list)) if len(steps_list) else math.nan
    collision_rate_per_step = (total_collisions / max(1, total_steps))

    summary = dict(
        episodes=episodes,
        success_rate=round(success_rate, 6),
        avg_steps=round(avg_steps, 3) if not math.isnan(avg_steps) else None,
        collision_per_step=round(collision_rate_per_step, 6),
        device=device_t,
        seed=42,
        per_episode_seed=per_episode_seed,
        assist_astar=assist_astar,
        max_steps_mult=max_steps_mult,
        easy_first=easy_first,
        created_at=datetime.now().isoformat(timespec="seconds"),
        weights_path=str(weights_path),
    )

    with open(json_path, "w", encoding="utf-8") as jf:
        json.dump(summary, jf, ensure_ascii=False, indent=2)

    print("\n===== Evaluation Summary =====")
    print(json.dumps(summary, ensure_ascii=False, indent=2))
    print(f"\nğŸ“„ CSV: {csv_path}")
    print(f"ğŸ§¾ JSON: {json_path}")


def parse_args():
    p = argparse.ArgumentParser()
    p.add_argument("--weights", type=str, required=True, help="æ¨¡å‹/æ™ºèƒ½ä½“æƒé‡è·¯å¾„ï¼ˆ.pt/.pthï¼‰")
    p.add_argument("--episodes", type=int, default=100)
    p.add_argument("--device", type=str, default="cuda", choices=["cpu","cuda"])
    p.add_argument("--out-dir", type=str, default="eval_runs")
    p.add_argument("--per-episode-seed", action="store_true")

    # æ–°å¢
    p.add_argument("--assist-astar", action="store_true", help="éç›®æ ‡æ™ºèƒ½ä½“ä½¿ç”¨ A* è¡Œä¸ºï¼ˆä¸å¸¸è§è®­ç»ƒè®¾ç½®å¯¹é½ï¼‰")
    p.add_argument("--max-steps-mult", type=int, default=4, help="max_episode_steps = mult * sizeï¼ˆå»ºè®® 3~6ï¼‰")
    p.add_argument("--easy-first", action="store_true", help="å…ˆåœ¨æ˜“å›¾é‡‡æ ·ï¼Œè¾¾æ ‡åè‡ªåŠ¨è§£é”éš¾å›¾")

    return p.parse_args()


if __name__ == "__main__":
    args = parse_args()
    evaluate_random(
        weights_path=args.weights,
        episodes=args.episodes,
        device=args.device,
        out_dir=args.out_dir,
        per_episode_seed=args.per_episode_seed,
        assist_astar=args.assist_astar,
        max_steps_mult=args.max_steps_mult,
        easy_first=args.easy_first,
    )
