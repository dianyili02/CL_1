# -*- coding: utf-8 -*-
import os, sys, argparse, random, inspect, math
from typing import Dict, List, Tuple, Optional
from collections import defaultdict



import numpy as np
import pandas as pd
import torch
import yaml
from tqdm import tqdm
import matplotlib.pyplot as plt
from pogema import AStarAgent

# --- é¡¹ç›®è·¯å¾„ ---
project_root = r"C:/Users/MSc_SEIoT_1/MAPF_G2RL-main"
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from g2rl.environment import G2RLEnv
from g2rl.agent import DDQNAgent
from g2rl.network import CRNNModel
from g2rl import moving_cost, detour_percentage

# --- ä½ è®­ç»ƒæ—¶çš„ complexity å…¬å¼ï¼ˆä¸è®­ç»ƒä¿æŒä¸€è‡´ï¼‰ ---
from g2rl.complexity_module import compute_map_complexity

INTERCEPT = 0.848
WEIGHTS = {
    'Size': 0.021,
    'Agents': -0.010,
    'Density': 0.077,
    'Density_actual': 0.132,
    'LDD': 0.027,
    'BN': -0.128,
    'MC': 0.039,
    'DLR': 0.002,
}
FEATURE_MEAN_STD = None  # è‹¥è®­ç»ƒæ—¶åšè¿‡æ ‡å‡†åŒ–å°±åœ¨æ­¤å¡«å…¥
import os
import numpy as np
import matplotlib.pyplot as plt

def plot_overall_success(out_dir: str, df_all, win: int = 10):
    """
    ç”»â€œæ‰€æœ‰åœ°å›¾çš„æ€»ä½“å¹³å‡è¶‹åŠ¿â€ï¼š
    - x è½´ï¼šepisode ç´¢å¼•ï¼ˆ0..episodes_per_map-1ï¼‰
    - y è½´ï¼šè¯¥ episode ç´¢å¼•ä¸‹è·¨æ‰€æœ‰åœ°å›¾çš„å¹³å‡æˆåŠŸç‡
    - åŒæ—¶ç”» rolling meanï¼ˆçª—å£ winï¼‰å’Œ Â±1 æ ‡å‡†å·®å¸¦
    """
    if "episode" not in df_all.columns or "success" not in df_all.columns:
        print("âš ï¸ df_all ç¼ºå°‘ episode æˆ– success åˆ—ï¼Œè·³è¿‡ overall æˆåŠŸç‡æ›²çº¿ã€‚")
        return

    # 1) æŒ‰ episode ç´¢å¼•èšåˆï¼Œå¾—åˆ°è·¨åœ°å›¾çš„å‡å€¼/æ ‡å‡†å·®
    g_mean = df_all.groupby("episode")["success"].mean().reset_index(name="mean_sr")
    g_std  = df_all.groupby("episode")["success"].std().reset_index(name="std_sr")
    g = g_mean.merge(g_std, on="episode", how="left").fillna(0.0)

    # 2) æ»šåŠ¨å¹³å‡ï¼ˆå¹³æ»‘æ€»ä½“è¶‹åŠ¿ï¼‰
    roll = g["mean_sr"].rolling(win, min_periods=1).mean()

    # 3) ç”»å›¾
    plt.figure(figsize=(10, 5))
    plt.plot(g["episode"], g["mean_sr"], label="Mean Success Rate", linewidth=1.5)
    plt.plot(g["episode"], roll, label=f"Rolling Mean (w={win})", linewidth=2)

    # Â±1 æ ‡å‡†å·®å¸¦ï¼ˆè£å‰ªåˆ° [0,1] æ›´ç›´è§‚ï¼‰
    lo = np.clip(g["mean_sr"] - g["std_sr"], 0.0, 1.0)
    hi = np.clip(g["mean_sr"] + g["std_sr"], 0.0, 1.0)
    plt.fill_between(g["episode"], lo, hi, alpha=0.15, label="Â±1 std")

    plt.xlabel("Episode index (per map)")
    plt.ylabel("Success rate")
    plt.title("Overall Episode Success Across Maps")
    plt.grid(True, alpha=0.3)
    plt.legend()
    os.makedirs(out_dir, exist_ok=True)
    out_path = os.path.join(out_dir, "overall_success.png")
    plt.tight_layout(); plt.savefig(out_path, dpi=150); plt.close()
    print(f"ğŸ“ˆ Overall æˆåŠŸç‡æ›²çº¿å·²ä¿å­˜ï¼š{out_path}")

# ---------- éšæœºåœ°å›¾ç”Ÿæˆ ----------
def sample_random_specs(
    n_maps: int,
    *,
    size_range=(16, 64),
    agents_choices=(2, 4, 8, 16),
    density_range=(0.05, 0.45),
    seed: int = 0
) -> Dict[str, dict]:
    rng = random.Random(seed)
    specs = {}
    for i in range(n_maps):
        size = rng.randint(size_range[0], size_range[1])
        num_agents = rng.choice(agents_choices)
        density = rng.uniform(density_range[0], density_range[1])

        # G2RLEnv: å½“ map=None æ—¶ä¼šæŒ‰ size / density éšæœºç”Ÿæˆæ–°ç½‘æ ¼
        spec = dict(
            map=None,
            size=int(size),
            density=float(density),
            num_agents=int(num_agents),
            obs_radius=7,
            cache_size=4,
            r1=-0.01, r2=-0.1, r3=0.1,
            seed=rng.randint(1, 10**9),
            animation=False,
            collission_system='soft',
            on_target='restart',
            max_episode_steps=64
        )

        # è®¡ç®— complexityï¼ˆä»…ç”¨åŸºç¡€ä¿¡æ¯ï¼›optional LDD/BN/MC/DLR æ²¡æœ‰ç½‘æ ¼æ—¶å¯ä¸ç®—ï¼‰
        try:
            cpx, used, raw = compute_map_complexity(
                spec, intercept=INTERCEPT, weights=WEIGHTS,
                feature_mean_std=FEATURE_MEAN_STD, size_mode="max"
            )
            spec["complexity"] = float(cpx)
        except Exception:
            spec["complexity"] = np.nan

        specs[f"rand_{i}"] = spec
    return specs

# ---------- æ„é€  Envï¼ˆè¿‡æ»¤ __init__ ä¸è®¤è¯†çš„é”®ï¼‰ ----------
def build_env_from_raw(raw_cfg: dict) -> G2RLEnv:
    sig = inspect.signature(G2RLEnv.__init__)
    allowed = {
        p.name for p in sig.parameters.values()
        if p.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD, inspect.Parameter.KEYWORD_ONLY)
    }
    allowed.discard("self")

    rename = {}  # å¦‚æœ‰å‘½åå·®å¼‚åœ¨æ­¤æ˜ å°„
    ctor_cfg = {}
    for k, v in raw_cfg.items():
        kk = rename.get(k, k)
        if kk in allowed:
            ctor_cfg[kk] = v
    env = G2RLEnv(**ctor_cfg)

    # é™„åŠ ä¸è¿› __init__ çš„å­—æ®µï¼ˆè¿™é‡Œæ²¡æœ‰ grid/starts/goalsï¼Œå› ä¸ºæ˜¯éšæœºç”Ÿæˆï¼‰
    return env

# ---------- è½½å…¥æ¨¡å‹ ----------
def load_model(pt_path, device="cuda"):
    device_t = torch.device("cuda" if (device=="cuda" and torch.cuda.is_available()) else "cpu")
    model = CRNNModel().to(device_t)
    ckpt = torch.load(pt_path, map_location=device_t)

    # å…¼å®¹å­—å…¸/æ•´åŒ…
    if isinstance(ckpt, dict) and "state_dict" in ckpt:
        sd = ckpt["state_dict"]
    elif isinstance(ckpt, dict) and "model" in ckpt and isinstance(ckpt["model"], dict):
        sd = ckpt["model"]
    elif isinstance(ckpt, dict):
        sd = ckpt
    else:
        raise RuntimeError("Unsupported checkpoint format.")

    missing, unexpected = model.load_state_dict(sd, strict=False)
    print(f"load_state_dict: missing={missing}, unexpected={unexpected}")
    model.eval()
    return model, device_t



# ---------- è¯„ä¼°ä¸€å¼ éšæœºåœ°å›¾ ----------
@torch.no_grad()
# def evaluate_on_map(
#     model: torch.nn.Module,
#     map_name: str,
#     spec: Dict,
#     episodes: int = 20,
#     device: str = "cuda",
#     max_steps: int = 200,
#     max_steps_fn=lambda ep: 50 + 10 * ep
# ) -> Tuple[pd.DataFrame, Dict[str, float]]:
#     model.eval()                # å…³æ‰ Dropout/BN
#     device_t = torch.device("cuda" if (device == "cuda" and torch.cuda.is_available()) else "cpu")
#     env = build_env_from_raw(spec)
#     n_actions = len(env.get_action_space())
#     agent = DDQNAgent(model=model, action_space=list(range(n_actions)), device=device_t)

# # â€”â€” å¼ºåˆ¶æ— æ¢ç´¢ï¼Œæ— è®­ç»ƒ â€”â€” 
#     if hasattr(agent, "epsilon"):      agent.epsilon = 0.0
#     if hasattr(agent, "epsilon_min"):  agent.epsilon_min = 0.0
#     if hasattr(agent, "train_mode"):   agent.train_mode = False   # å¦‚æœç±»é‡Œæœ‰è¿™ä¸ªå¼€å…³
#     if hasattr(agent, "eval_mode"):    agent.eval_mode = True     # åŒä¸Š
#     # if hasattr(agent, "replay_buffer"): agent.replay_buffer.clear()
#     if hasattr(agent, "retrain"):      
#     # ç¡®ä¿è¯„æµ‹å¾ªç¯é‡Œç»å¯¹ä¸è°ƒç”¨ retrain()
#         pass


#     env = build_env_from_raw(spec)
#     action_space = env.get_action_space()
#     agent = DDQNAgent(model=model, action_space=action_space, device=device)

#     logs = []
#     succ_list, steps_list, rew_list, mv_list, dt_list = [], [], [], [], []

#     for ep in tqdm(range(episodes), desc=f"Eval {map_name}", dynamic_ncols=True):
#         obs, info = env.reset()
#         tgt: int = np.random.randint(env.num_agents)
#         target_idx = np.random.randint(env.num_agents)
#         agents = [agent if i == target_idx else AStarAgent() for i in range(env.num_agents)]
#         goal = tuple(env.goals[target_idx])
#         state = obs[target_idx]
#         opt_path = [state['global_xy']] + env.global_guidance[target_idx]

#         success = False
#         total_reward = 0.0
#         T = int(max_steps_fn(ep))
#         mv = float("nan")
#         dt = float("nan")
#         steps = max_steps  # é»˜è®¤å€¼ï¼Œå¦‚æœå¾ªç¯é‡Œæ²¡ break å°±ç”¨ max_steps
#         for t in range(max_steps):
#             actions = [a.act(o) for a, o in zip(agents, obs)]
#             obs, reward, terminated, truncated, info = env.step(actions)
#             total_reward += float(reward[tgt])

#             pos = tuple(obs[tgt]['global_xy'])
#             if pos == goal:
#                 success = True
#                 steps = t + 1  # æå‰æˆåŠŸï¼Œè®°å½•å®é™…æ­¥æ•°
#                 break
#         else:
#     # å¦‚æœæ²¡æœ‰ breakï¼ˆå³å¤±è´¥ï¼‰ï¼Œsteps ä¿æŒ max_steps
#             steps = max_steps


#         succ_list.append(1 if success else 0)
#         steps_list.append(t + 1)
#         rew_list.append(total_reward)

#         logs.append({
#             "map": map_name,
#             "agents": env.num_agents,
#             "size": spec.get("size", np.nan),
#             "density": spec.get("density", np.nan),
#             "LDD": spec.get("LDD", np.nan),
#             "BN": spec.get("BN", np.nan),
#             "MC": spec.get("MC", np.nan),
#             "DLR": spec.get("DLR", np.nan),
#             "complexity": spec.get("complexity", np.nan),
#             "episode": ep,
#             "success": int(success),
#             "steps": int(steps),
#             "reward": float(total_reward),
#             "moving_cost": float(mv),
#             "detour_pct": float(dt),
#         })

#     df = pd.DataFrame(logs)
#     summary = {
#         "map": map_name,
#         "size": spec.get("size", np.nan),
#         "density": spec.get("density", np.nan),
#         "LDD": spec.get("LDD", np.nan),
#         "BN": spec.get("BN", np.nan),
#         "MC": spec.get("MC", np.nan),
#         "DLR": spec.get("DLR", np.nan),
#         "agents": spec.get("num_agents", env.num_agents),
#         "complexity": spec.get("complexity", np.nan),
#         "episodes": len(df),
#         "success_rate": float(df["success"].mean()) if len(df) else np.nan,
#         "avg_steps": float(df["steps"].mean()) if len(df) else np.nan,
#         "avg_reward": float(df["reward"].mean()) if len(df) else np.nan,
#         "avg_moving_cost": float(df["moving_cost"].mean()) if len(df) else np.nan,
#         "avg_detour_pct": float(df["detour_pct"].mean()) if len(df) else np.nan,
#     }
#     return df, summary



def evaluate_on_map(
    model: torch.nn.Module,
    map_name: str,
    spec: Dict,
    episodes: int = 20,
    device: str = "cuda",
    max_steps: int = 200,
    max_steps_fn=lambda ep: 50 + 10 * ep
) -> Tuple[pd.DataFrame, Dict[str, float]]:
    """
    åœ¨æŒ‡å®šåœ°å›¾ spec ä¸Šè¯„æµ‹è‹¥å¹² episodeï¼Œè¿”å› (episode-level DataFrame, per-map summary dict)ã€‚
    - è¯„æµ‹é˜¶æ®µï¼šæ— æ¢ç´¢ã€æ— è®­ç»ƒï¼ˆä¸è°ƒç”¨ store/retrainï¼‰ã€‚
    - æ— è®ºæˆåŠŸä¸å¦ï¼Œéƒ½ä¼šè®¡ç®— moving_cost / detour_pct ä¾¿äºæ¨ªå‘æ¯”è¾ƒã€‚
    """
    model.eval()  # å…³é—­ Dropout/BN
    device_t = torch.device("cuda" if (device == "cuda" and torch.cuda.is_available()) else "cpu")

    # åªæ„é€ ä¸€æ¬¡ç¯å¢ƒä¸æ™ºèƒ½ä½“
    env = build_env_from_raw(spec)
    n_actions = len(env.get_action_space())
    agent = DDQNAgent(model=model, action_space=list(range(n_actions)), device=device_t)

    # â€”â€” å¼ºåˆ¶æ— æ¢ç´¢ï¼Œæ— è®­ç»ƒ â€”â€”
    if hasattr(agent, "epsilon"):     agent.epsilon = 0.0
    if hasattr(agent, "epsilon_min"): agent.epsilon_min = 0.0
    if hasattr(agent, "train_mode"):  agent.train_mode = False
    if hasattr(agent, "eval_mode"):   agent.eval_mode = True
    # ä¸è¦è°ƒç”¨ agent.store / agent.retrain

    logs = []

    for ep in tqdm(range(episodes), desc=f"Eval {map_name}", dynamic_ncols=True):
        obs, info = env.reset()

        # éšæœºé€‰ä¸€ä¸ªè¢« DDQN æ§åˆ¶çš„ agentï¼›å…¶ä½™ç”¨ A* baseline
        tgt = np.random.randint(env.num_agents)
        goal = tuple(env.goals[tgt])
        state = obs[tgt]

        # æœ€çŸ­è·¯ï¼ˆenv åœ¨ reset æ—¶å·²ç®—å¥½ global_guidanceï¼‰
        opt_path = [state['global_xy']] + env.global_guidance[tgt]
        opt_len = max(1, len(opt_path) - 1)  # é¿å… 0

        agents = [agent if i == tgt else AStarAgent() for i in range(env.num_agents)]

        success = False
        total_reward = 0.0

        # æœ¬é›†æ­¥æ•°ä¸Šé™ï¼šè‹¥æä¾›äº† max_steps_fnï¼Œç”¨å®ƒï¼›å¦åˆ™ç”¨å›ºå®š max_steps
        this_max_steps = int(max_steps_fn(ep)) if max_steps_fn is not None else int(max_steps)

        steps = this_max_steps  # å…ˆç»™é»˜è®¤å€¼ï¼ˆå¤±è´¥æ—¶ä¼šç”¨ï¼‰
        for t in range(this_max_steps):
            actions = [a.act(o) for a, o in zip(agents, obs)]
            obs, reward, terminated, truncated, info = env.step(actions)
            total_reward += float(reward[tgt])

            # æ˜¯å¦åˆ°è¾¾
            if tuple(obs[tgt]['global_xy']) == goal:
                success = True
                steps = t + 1  # è®°å½•çœŸå®ç”¨æ—¶
                break

        # ç»Ÿä¸€è®¡ç®—æŒ‡æ ‡ï¼ˆæˆåŠŸä¸å¦éƒ½ç®—ï¼Œä¾¿äºå¯¹æ¯”ï¼‰
        mv = moving_cost(steps, opt_path[0], opt_path[-1])
        dt = detour_percentage(steps, opt_len)

        logs.append({
            "map": map_name,
            "agents": env.num_agents,
            "size": spec.get("size", np.nan),
            "density": spec.get("density", np.nan),
            "LDD": spec.get("LDD", np.nan),
            "BN": spec.get("BN", np.nan),
            "MC": spec.get("MC", np.nan),
            "DLR": spec.get("DLR", np.nan),
            "complexity": spec.get("complexity", np.nan),
            "episode": ep,
            "success": int(success),
            "steps": int(steps),
            "reward": float(total_reward),
            "moving_cost": float(mv),
            "detour_pct": float(dt),
        })

    df = pd.DataFrame(logs)

    summary = {
        "map": map_name,
        "size": spec.get("size", np.nan),
        "density": spec.get("density", np.nan),
        "LDD": spec.get("LDD", np.nan),
        "BN": spec.get("BN", np.nan),
        "MC": spec.get("MC", np.nan),
        "DLR": spec.get("DLR", np.nan),
        "agents": spec.get("num_agents", env.num_agents),
        "complexity": spec.get("complexity", np.nan),
        "episodes": len(df),
        "success_rate": float(df["success"].mean()) if len(df) else np.nan,
        "avg_steps": float(df["steps"].mean()) if len(df) else np.nan,
        "avg_reward": float(df["reward"].mean()) if len(df) else np.nan,
        "avg_moving_cost": float(df["moving_cost"].mean()) if len(df) else np.nan,
        "avg_detour_pct": float(df["detour_pct"].mean()) if len(df) else np.nan,
    }
    return df, summary


# ---------- å¯è§†åŒ– ----------
def _rolling_mean(x, w=50):
    if len(x) == 0:
        return np.array([])
    w = max(1, int(w))
    c = np.cumsum(np.insert(x, 0, 0))
    rm = (c[w:] - c[:-w]) / float(w)
    head = [np.mean(x[:i+1]) for i in range(min(w-1, len(x)))]
    return np.array(head + rm.tolist())

def make_plots(out_dir: str, df_all: pd.DataFrame, df_sum: pd.DataFrame, buckets: int = 5):
    os.makedirs(out_dir, exist_ok=True)

    # æˆåŠŸç‡ vs å¤æ‚åº¦ï¼ˆæŒ‰åœ°å›¾ï¼‰
    dfp = df_sum.dropna(subset=["complexity"]).sort_values("complexity")
    if len(dfp):
        plt.figure(figsize=(8,5))
        x, y = dfp["complexity"].values, dfp["success_rate"].values
        plt.scatter(x, y, s=40)
        if len(x) >= 2 and np.isfinite(x).all() and np.isfinite(y).all():
            coef = np.polyfit(x, y, 1); xx = np.linspace(x.min(), x.max(), 200); yy = np.polyval(coef, xx)
            plt.plot(xx, yy, linewidth=2)
        plt.xlabel("Complexity"); plt.ylabel("Success Rate"); plt.title("Success Rate vs Complexity (per map)")
        plt.grid(True, alpha=0.3); plt.tight_layout()
        plt.savefig(os.path.join(out_dir, "success_vs_complexity_scatter.png"), dpi=150); plt.close()

    # æˆåŠŸç‡åˆ†æ¡¶ï¼ˆæŒ‰å¤æ‚åº¦ï¼‰
    if len(df_sum) and df_sum["complexity"].notna().any():
        dd = df_sum.dropna(subset=["complexity"]).copy()
        edges = np.quantile(dd["complexity"].values, np.linspace(0, 1, buckets+1))
        dd["bucket"] = pd.cut(dd["complexity"], bins=edges, include_lowest=True, right=False)
        sr_by_bucket = dd.groupby("bucket")["success_rate"].mean()
        plt.figure(figsize=(8,5)); sr_by_bucket.plot(kind="bar")
        plt.ylabel("Mean Success Rate"); plt.title(f"Success Rate by Complexity Bucket (maps, buckets={buckets})")
        plt.tight_layout(); plt.savefig(os.path.join(out_dir, "success_rate_buckets.png"), dpi=150); plt.close()

    # æ¯é›†ï¼šæˆåŠŸï¼ˆ0/1ï¼‰ä¸æ»‘çª— SR
    if len(df_all):
        ep = df_all["episode"].values; succ = df_all["success"].values.astype(float)
        plt.figure(figsize=(10,5))
        plt.plot(ep, succ, label="Success (0/1)", linewidth=1)
        rm = _rolling_mean(succ, w=50)
        if len(rm) > 0:
            plt.plot(ep[:len(rm)], rm, linewidth=2, label="Rolling SR (w=50)")
        plt.xlabel("Episode"); plt.ylabel("Success / SR"); plt.title("Episode Success & Rolling SR")
        plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout()
        plt.savefig(os.path.join(out_dir, "episode_sr_curve.png"), dpi=150); plt.close()
    
    plot_overall_success(out_dir, df_all, win=10)
import pandas as pd

def summarize_results(episode_logs, out_csv=None, pbar=None):
    """
    æ ¹æ® episode æ—¥å¿—ç”Ÿæˆ per-map summaryã€‚
    episode_logs: List[dict] or pd.DataFrame
        æ¯æ¡æ—¥å¿—è‡³å°‘åŒ…å«è¿™äº›å­—æ®µ:
        - map
        - agents
        - complexity
        - steps
        - reward
        - moving_cost (å¯é€‰)
        - detour_pct (å¯é€‰)
        - success (0/1)
    """
    df = pd.DataFrame(episode_logs)

    # æ¯ä¸ª map ç»Ÿè®¡
    summary = df.groupby(["map", "agents", "complexity", "size", "density", "LDD", "BN", "MC", "DLR"]).agg(
        episodes=("success", "count"),
        success_rate=("success", "mean"),
        avg_steps=("steps", "mean"),
        avg_reward=("reward", "mean"),
        avg_moving_cost=("moving_cost", "mean"),
        avg_detour_pct=("detour_pct", "mean"),
    ).reset_index()

    # æ’åº (æŒ‰ complexity)
    summary = summary.sort_values("complexity")

    # ç¾è§‚æ‰“å°
    print("\n===== Summary (per-map) =====")
    print(summary.to_string(index=False, float_format=lambda x: f"{x:.3f}"))

    # å¯é€‰ä¿å­˜åˆ° CSV
    if out_csv:
        summary.to_csv(out_csv, index=False)
        if pbar:
            pbar.write(f"ğŸ’¾ Saved per-map summary to {out_csv}")

    return summary


def summarize_overall_success(df_all: pd.DataFrame, out_csv: str = None) -> pd.DataFrame:
    """
    è¾“å‡ºæ•´ä½“ Success Rateï¼Œå¹¶é™„å¸¦ä¸€äº›å¸¸è§åˆ‡ç‰‡ï¼ˆæŒ‰ agentsã€æŒ‰ complexity æ¡¶ï¼‰ã€‚
    è¿”å›ä¸€ä¸ª DataFrameï¼ˆ1 è¡Œæ•´ä½“ + å¤šè¡Œåˆ†ç»„ï¼‰ã€‚
    """
    if df_all.empty:
        print("âš ï¸ æ²¡æœ‰è¯„æµ‹æ•°æ®ï¼Œæ— æ³•ç»Ÿè®¡æ•´ä½“æˆåŠŸç‡ã€‚")
        return pd.DataFrame()

    rows = []

    # â€”â€” Overall â€”â€” #
    overall_sr = df_all["success"].mean()
    rows.append({
        "scope": "OVERALL",
        "key": "ALL",
        "episodes": int(len(df_all)),
        "success_rate": float(overall_sr),
    })

    # â€”â€” æŒ‰ agents åˆ‡ç‰‡ â€”â€” #
    if "agents" in df_all.columns:
        g = df_all.groupby("agents")["success"].mean().reset_index()
        for _, r in g.iterrows():
            rows.append({
                "scope": "BY_AGENTS",
                "key": int(r["agents"]),
                "episodes": int((df_all["agents"] == r["agents"]).sum()),
                "success_rate": float(r["success"]),
            })

    # â€”â€” æŒ‰ complexity åˆ†æ¡¶ï¼ˆ5 æ¡¶ï¼‰ â€”â€” #
    if "complexity" in df_all.columns and df_all["complexity"].notna().any():
        d = df_all.dropna(subset=["complexity"]).copy()
        edges = np.quantile(d["complexity"].values, np.linspace(0, 1, 6))  # 5 æ¡¶
        d["cpx_bucket"] = pd.cut(d["complexity"], bins=edges, include_lowest=True, right=False)
        g = d.groupby("cpx_bucket")["success"].mean().reset_index()
        for _, r in g.iterrows():
            rows.append({
                "scope": "BY_COMPLEXITY_BUCKET",
                "key": str(r["cpx_bucket"]),
                "episodes": int((d["cpx_bucket"] == r["cpx_bucket"]).sum()),
                "success_rate": float(r["success"]),
            })

    df_metrics = pd.DataFrame(rows)
    # ç¾è§‚æ‰“å°
    print("\n===== Overall Test Success Rate =====")
    print(df_metrics.to_string(index=False, float_format=lambda x: f"{x:.3f}"))

    if out_csv:
        df_metrics.to_csv(out_csv, index=False, encoding="utf-8-sig")
        print(f"ğŸ’¾ å·²ä¿å­˜æ•´ä½“/åˆ‡ç‰‡æˆåŠŸç‡ï¼š{out_csv}")

    return df_metrics

# ---------- ä¸»å…¥å£ ----------
def main():
    ap = argparse.ArgumentParser("Test trained model on RANDOMLY GENERATED maps")
    ap.add_argument("--pt", type=str, required=True, help="æ¨¡å‹è·¯å¾„ï¼Œå¦‚ models/model1.pt")
    ap.add_argument("--out_dir", type=str, default="eval_random", help="è¾“å‡ºç›®å½•")
    ap.add_argument("--device", type=str, default="cuda", choices=["cuda","cpu"])
    ap.add_argument("--n_maps", type=int, default=20, help="éšæœºç”Ÿæˆå¤šå°‘å¼ ä¸åŒåœ°å›¾")
    ap.add_argument("--episodes_per_map", type=int, default=30, help="æ¯å¼ åœ°å›¾è¯„ä¼°å¤šå°‘å›åˆ")
    ap.add_argument("--size_min", type=int, default=16)
    ap.add_argument("--size_max", type=int, default=64)
    ap.add_argument("--agents", type=int, nargs="+", default=[2,4,8,16])
    ap.add_argument("--dens_min", type=float, default=0.05)
    ap.add_argument("--dens_max", type=float, default=0.45)
    ap.add_argument("--seed", type=int, default=0)
    ap.add_argument("--max_steps", type=int, default=200, help="æ¯é›†æœ€å¤§æ­¥æ•°ï¼ˆå›ºå®šä¸Šé™ï¼‰")
    ap.add_argument("--stamp_dir", action="store_true", help="åœ¨ out_dir ä¸‹å†åŠ æ—¶é—´æˆ³å­ç›®å½•ï¼Œé¿å…è¦†ç›–")
    args = ap.parse_args()


    if args.stamp_dir:
        from datetime import datetime
        stamp = datetime.now().strftime('%H-%M-%d-%m-%Y')
        out_dir = os.path.join(args.out_dir, stamp)
    else:
        out_dir = args.out_dir
    os.makedirs(out_dir, exist_ok=True)
    # os.makedirs(args.out_dir, exist_ok=True)

    # 1) è½½å…¥å·²è®­ç»ƒæ¨¡å‹
    model, device_t = load_model(args.pt, device=args.device)

    # 2) éšæœºç”Ÿæˆåœ°å›¾è§„èŒƒ
    specs = sample_random_specs(
        args.n_maps,
        size_range=(args.size_min, args.size_max),
        agents_choices=tuple(args.agents),
        density_range=(args.dens_min, args.dens_max),
        seed=args.seed
    )

    # 3) è¯„ä¼°
    all_rows = []
    for name, spec in specs.items():
        df_ep, _summ = evaluate_on_map(
            model, name, spec, episodes=args.episodes_per_map, device=str(device_t)
        )
        all_rows.append(df_ep)
        # é€å›¾ä¿å­˜ episode çº§åˆ«æ—¥å¿—
        df_ep.to_csv(os.path.join(args.out_dir, f"{name}_episodes.csv"), index=False, encoding="utf-8-sig")

    # åˆå¹¶æ‰€æœ‰ episode çº§åˆ«æ—¥å¿—
    df_all = pd.concat(all_rows, ignore_index=True) if all_rows else pd.DataFrame()
    all_ep_csv = os.path.join(args.out_dir, "all_episodes.csv")
    df_all.to_csv(all_ep_csv, index=False, encoding="utf-8-sig")

    # 4) ç”Ÿæˆ per-map æ±‡æ€»ï¼ˆä½ è¦çš„ summary è¡¨ï¼‰
    # 4) ç”Ÿæˆ per-map æ±‡æ€»
    summary_csv = os.path.join(out_dir, "summary.csv")
    df_sum = summarize_results(df_all, out_csv=summary_csv)

# 5) ç»Ÿè®¡æµ‹è¯•ç¯èŠ‚æˆåŠŸç‡ï¼ˆæ•´ä½“ + æŒ‰ agents + æŒ‰ complexity æ¡¶ï¼‰
    overall_csv = os.path.join(out_dir, "overall_success.csv")
    df_overall = summarize_overall_success(df_all, out_csv=overall_csv)

# 6) å¯è§†åŒ–ï¼ˆå¦‚æœæœ‰ make_plotsï¼‰
    try:
        make_plots(out_dir, df_all, df_sum, buckets=5)
        print(f"\nğŸ“Š å¯è§†åŒ–å·²ä¿å­˜åˆ°ï¼š{out_dir}")
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å¤±è´¥ï¼š{e}")


    # 5) å¯è§†åŒ–
    try:
        make_plots(args.out_dir, df_all, df_sum, buckets=5)
        print(f"\nğŸ“Š å¯è§†åŒ–å·²ä¿å­˜åˆ°ï¼š{args.out_dir}")
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å¤±è´¥ï¼š{e}")

if __name__ == "__main__":
    main()

