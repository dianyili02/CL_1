import pandas as pd
import yaml
import numpy as np
import json
import os


# æ–‡ä»¶è·¯å¾„
YAML_PATH = "C:/Users/MSc_SEIoT_1/MAPF_G2RL-main - train/g2rl/map_settings_generated_new.yaml"
CSV_IN = "C:/Users/MSc_SEIoT_1/MAPF_G2RL-main/logs/train_gray3d-Copy.csv"
CSV_OUT = "C:/Users/MSc_SEIoT_1/MAPF_G2RL-main - train/train_gray3d-Copy.csv"


# ---------- å·¥å…· ----------
def to_grid(arr):
    g = np.array(arr, dtype=np.uint8)
    if g.ndim != 2:
        raise ValueError("grid must be 2D")
    return (g > 0).astype(np.uint8)

def compute_FRA(grid: np.ndarray) -> float:
    H, W = grid.shape
    free = np.argwhere(grid == 0)
    if free.size == 0:
        return 0.0
    total = 0.0
    for x, y in free:
        neigh = free_neigh = 0
        for dx, dy in [(-1,0),(1,0),(0,-1),(0,1)]:
            nx, ny = x+dx, y+dy
            if 0 <= nx < H and 0 <= ny < W:
                neigh += 1
                if grid[nx, ny] == 0:
                    free_neigh += 1
        if neigh > 0:
            total += free_neigh / neigh
    return float(total / len(free))

def compute_FDA_from_grid(grid: np.ndarray) -> float:
    return float((grid == 0).sum() / grid.size)

def pick_name_column(df: pd.DataFrame):
    candidates = ["map_name", "name", "map", "map_id", "Map", "Name"]
    for c in candidates:
        if c in df.columns:
            return c
    return None

def parse_config_json_column(df: pd.DataFrame):
    """è‹¥ CSV æœ‰ config_json åˆ—ï¼Œå°†å…¶ä¸­çš„ size/num_agents/density/obs_radius/max_episode_steps è§£æå‡ºæˆåˆ—ã€‚"""
    if "config_json" not in df.columns:
        return df
    # é¿å…ç ´ååŸ DataFrame
    df = df.copy()
    ks = ["size","num_agents","density","obs_radius","max_episode_steps"]
    # è‹¥å·²å­˜åœ¨è¿™äº›åˆ—åˆ™ä¸è¦†ç›–
    need = [k for k in ks if k not in df.columns]
    if not need:
        return df
    parsed = {k: [] for k in need}
    for s in df["config_json"].astype(str).fillna("{}"):
        try:
            obj = json.loads(s)
        except Exception:
            obj = {}
        for k in need:
            parsed[k].append(obj.get(k, np.nan))
    for k in need:
        df[k] = parsed[k]
    return df

def round_float_cols(df: pd.DataFrame, cols, ndigits=6):
    df = df.copy()
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").round(ndigits)
    return df

# ---------- è¯»å– YAML ----------
with open(YAML_PATH, "r", encoding="utf-8") as f:
    ydata = yaml.safe_load(f)

# é¡¶å±‚ list -> dict
if isinstance(ydata, list):
    ydict = {(m.get("name") or f"map_{i}"): m for i, m in enumerate(ydata)}
elif isinstance(ydata, dict):
    ydict = ydata
else:
    raise ValueError("Unsupported YAML structure.")

# ---------- ä» YAML ç”Ÿæˆ FRA/FDA + é…ç½®é”® çš„è¡¨ ----------
rows = []
for key, spec in ydict.items():
    map_name = spec.get("name", key)

    # é…ç½®å­—æ®µï¼ˆå¯èƒ½ç”¨äºåˆå¹¶ï¼‰
    size  = spec.get("size", np.nan)
    nag   = spec.get("num_agents", np.nan)
    dens  = spec.get("density", spec.get("Density", np.nan))
    obsr  = spec.get("obs_radius", np.nan)
    msteps= spec.get("max_episode_steps", np.nan)

    fra = spec.get("FRA", None)
    fda = spec.get("FDA", None)

    grid = None
    if fra is None or fda is None:
        if "grid" in spec and spec["grid"] is not None:
            try:
                grid = to_grid(spec["grid"])
            except Exception:
                grid = None
        if fra is None:
            fra = compute_FRA(grid) if grid is not None else np.nan
        if fda is None:
            if grid is not None:
                fda = compute_FDA_from_grid(grid)
            else:
                try:
                    dens_f = float(dens) if dens is not None else np.nan
                except Exception:
                    dens_f = np.nan
                fda = (1.0 - dens_f) if pd.notna(dens_f) else np.nan

    rows.append({
        "map_name": map_name,
        "size": size,
        "num_agents": nag,
        "density": dens,
        "obs_radius": obsr,
        "max_episode_steps": msteps,
        "FRA": fra,
        "FDA": fda,
    })

ydf = pd.DataFrame(rows)

# ç»Ÿä¸€æ•°å€¼ç²¾åº¦é¿å…æµ®ç‚¹è¯¯å·®
num_keys = ["size","num_agents","density","obs_radius","max_episode_steps"]
ydf = round_float_cols(ydf, num_keys, ndigits=6)

# ---------- è¯»å– CSV ----------
df = pd.read_csv(CSV_IN)
df = parse_config_json_column(df)  # ä» config_json è§£æé…ç½®é”®ï¼ˆè‹¥æœ‰ï¼‰
df = round_float_cols(df, num_keys, ndigits=6)

# ---------- é€‰æ‹©åˆå¹¶ç­–ç•¥ ----------
name_col = pick_name_column(df)

merged = None
used_key = None

if name_col is not None and "map_name" in ydf.columns:
    # å…ˆç”¨åå­—åˆå¹¶
    merged = df.merge(ydf[["map_name","FRA","FDA"]].rename(columns={"map_name":name_col}),
                      on=name_col, how="left")
    used_key = f"name_col:{name_col}"

if merged is None:
    # å°è¯•ç”¨é…ç½®é”®åˆå¹¶ï¼ˆäº”åˆ—å…¨åœ¨æ‰ç”¨ï¼‰
    keyset = [k for k in num_keys if k in df.columns and k in ydf.columns]
    if set(["size","num_agents","density","obs_radius","max_episode_steps"]).issubset(set(keyset)):
        merged = df.merge(ydf[keyset + ["FRA","FDA"]], on=keyset, how="left")
        used_key = "config_keys: size,num_agents,density,obs_radius,max_episode_steps"

if merged is None and "config_json" in df.columns:
    # å…œåº•ï¼šå¦‚æœ parse å¤±è´¥æˆ–åˆ—ç¼ºå¤±ï¼Œä¹Ÿå°½é‡ç”¨èƒ½å¯¹é½çš„å­é›†
    keyset = [k for k in num_keys if k in df.columns and k in ydf.columns]
    if keyset:
        merged = df.merge(ydf[keyset + ["FRA","FDA"]], on=keyset, how="left")
        used_key = f"config_keys_subset: {keyset}"

if merged is None:
    raise KeyError(
        "æ— æ³•æ‰¾åˆ°å¯ç”¨äºåˆå¹¶çš„é”®ï¼\n"
        f"CSV åˆ—ï¼š{list(df.columns)}\n"
        f"YAML å¯ç”¨é”®ï¼š{num_keys} + map_name\n"
        "å»ºè®®ï¼šç¡®ä¿ CSV è‡³å°‘åŒ…å« size/num_agents/density/obs_radius/max_episode_steps è¿™äº”åˆ— "
        "æˆ–æä¾›åœ°å›¾ååˆ—ï¼ˆmap_name/name/map_idï¼‰ã€‚"
    )

# ç»Ÿè®¡åŒ¹é…æƒ…å†µ
miss = merged["FRA"].isna().sum()
print(f"ğŸ”— Merge key used: {used_key}")
print(f"âœ… åˆå¹¶å®Œæˆï¼šæ€»è¡Œæ•° {len(merged)}ï¼Œå…¶ä¸­ FRA/FDA ç¼ºå¤±è¡Œæ•° {miss}")

# ---------- ä¿å­˜ ----------
os.makedirs(os.path.dirname(CSV_OUT) or ".", exist_ok=True)
merged.to_csv(CSV_OUT, index=False, encoding="utf-8-sig")
print(f"ğŸ’¾ å·²å†™å‡ºï¼š{CSV_OUT}")
