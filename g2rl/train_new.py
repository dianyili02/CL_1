#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional, Union
from collections import defaultdict
import os, sys, time, inspect, random, csv

import numpy as np
import pandas as pd
import torch
from torch.utils.tensorboard import SummaryWriter
import yaml
from tqdm import tqdm
import matplotlib.pyplot as plt
from pogema import AStarAgent

# ============ é¡¹ç›®æ ¹è·¯å¾„ ============
project_root = r"C:/Users/MSc_SEIoT_1/MAPF_G2RL-main - train"
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ============ é¡¹ç›®æ¨¡å— ============
from g2rl.environment import G2RLEnv
from g2rl.agent import DDQNAgent
from g2rl.network import CRNNModel
from g2rl import moving_cost, detour_percentage

# ============ åŸºç¡€å·¥å…· ============
def get_timestamp() -> str:
    return datetime.now().strftime('%H-%M-%d-%m-%Y')

def _np_grid(g):
    arr = np.array(g, dtype=np.uint8)
    if arr.ndim != 2:
        raise ValueError("grid must be 2D")
    return (arr > 0).astype(np.uint8)

def build_env_from_raw(raw_cfg: dict) -> G2RLEnv:
    """åªæŠŠ G2RLEnv.__init__ æ”¯æŒçš„é”®ä¼ å…¥ï¼Œgrid/starts/goals ç­‰æŒ‚å±æ€§ã€‚"""
    sig = inspect.signature(G2RLEnv.__init__)
    allowed = {
        p.name for p in sig.parameters.values()
        if p.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD, inspect.Parameter.KEYWORD_ONLY)
    }
    allowed.discard("self")
    rename = {}  # å¦‚éœ€è¦åšé”®åæ˜ å°„å¯åœ¨æ­¤è¡¥å……ï¼ˆä¾‹å¦‚ {'size':'map_size'}ï¼‰

    ctor_cfg = {}
    for k, v in raw_cfg.items():
        kk = rename.get(k, k)
        if kk in allowed:
            ctor_cfg[kk] = v

    env = G2RLEnv(**ctor_cfg)

    # å°† grid/starts/goals ä½œä¸ºå±æ€§æŒ‚è½½ï¼ˆä¸è¿›å…¥ __init__ï¼‰
    if "grid" in raw_cfg:
        try:
            env.grid = _np_grid(raw_cfg["grid"])
        except Exception:
            env.grid = None
    if "starts" in raw_cfg:
        env.starts = raw_cfg["starts"]
    if "goals" in raw_cfg:
        env.goals = raw_cfg["goals"]
    return env

def extract_features_from_spec(name: str, spec: dict) -> Dict[str, float]:
    """
    ä» YAML spec å’Œ grid ä¸­æŠ½å–ç”¨äºåˆ†æçš„ featuresã€‚
    ä¿ç•™ Size / Agents / Density / Density_actual + FRA/FDA/BN/LDD/MC/DLRï¼ˆè‹¥ YAML å·²æœ‰ï¼‰ã€‚
    """
    feats = {}
    feats["map_name"]   = name
    feats["Size"]       = float(spec.get("size", spec.get("Size", np.nan)))
    feats["Agents"]     = float(spec.get("num_agents", spec.get("Agents", np.nan)))
    feats["Density"]    = float(spec.get("density", spec.get("Density", np.nan)))

    # density_actualï¼šæŒ‰ grid çœŸå®éšœç¢å æ¯”ï¼ˆæœ‰ grid æ—¶è®¡ç®—ï¼‰
    try:
        if "grid" in spec and spec["grid"] is not None:
            g = _np_grid(spec["grid"])
            feats["Density_actual"] = float(g.mean())
        else:
            feats["Density_actual"] = np.nan
    except Exception:
        feats["Density_actual"] = np.nan

    # å…¶ä»–å¯é€‰ç‰¹å¾ï¼šFRA/FDA/BN/LDD/MC/DLRï¼ˆå¦‚æœ YAML å·²ç®—å¥½å°±å¸¦ä¸Šï¼‰
    for k in ["FRA", "FDA", "BN", "LDD", "MC", "DLR"]:
        if k in spec:
            try:
                feats[k] = float(spec[k])
            except Exception:
                feats[k] = np.nan
        else:
            feats[k] = np.nan
    return feats

# ============ æˆåŠŸåˆ¤å®šè¾…åŠ© ============
def _bool_from(x, idx: int) -> bool:
    """æŠŠ terminated/truncated è¿™ç±»å¤šä»£ç†è¿”å›è§„æ•´ä¸ºå•ä¸ª target çš„ boolã€‚"""
    if isinstance(x, (list, tuple, np.ndarray)):
        if len(x) == 0: 
            return False
        if 0 <= idx < len(x):
            return bool(x[idx])
        return bool(any(x))
    if isinstance(x, dict):
        # å¸¸è§å­—æ®µå°è¯•
        for key in (idx, "global", "any", "done", "terminated"):
            if key in x:
                try: return bool(x[key])
                except Exception: pass
        try:
            return bool(next(iter(x.values())))
        except Exception:
            return False
    try:
        return bool(x)
    except Exception:
        return False

def _success_from_info(info, idx: int) -> Optional[bool]:
    """ä» info ä¸­å°½å¯èƒ½æŠ½å–æˆåŠŸä¿¡å·ï¼›æŠ½ä¸åˆ°è¿”å› Noneã€‚"""
    if not isinstance(info, dict):
        return None
    cand = info.get(idx, info)  # æœ‰äº› env ä¼šæŒ‰ agent ç´¢å¼•ç»™å­ dict
    if isinstance(cand, dict):
        for k in ("success", "is_success", "solved", "reached_goal", "done"):
            if k in cand:
                try:
                    return bool(cand[k])
                except Exception:
                    pass
    return None

# ============ è¯„ä¼°ï¼šå•é›† ============
def run_one_episode(
    env: G2RLEnv, 
    agent: DDQNAgent, 
    episode_idx: int,
    max_episode_seconds: int = 30,
    max_steps_cap: Optional[int] = None
) -> Dict[str, float]:
    """
    å•é›† rolloutï¼šé€‰ä¸€ä¸ª target agentï¼ˆå…¶ä½™ç”¨ A*ï¼‰ã€‚
    æˆåŠŸåˆ¤å®šä¼˜å…ˆé¡ºåºï¼š
      1) ç›®æ ‡ä»£ç†ä½ç½® == è‡ªèº« goal
      2) env çš„ info/terminated/truncated ç»™å‡ºçš„æˆåŠŸä¿¡å·
    åŒæ—¶å¯ç”¨ä¸¤ç§â€œè¶…æ—¶ä¿æŠ¤â€ï¼šå¢™é’Ÿæ—¶é—´ + æ­¥æ•°ä¸Šé™ï¼ˆä»»ä½•ä¸€ä¸ªè§¦å‘å³å¤±è´¥ï¼‰
    """
    try:
        obs, info = env.reset()
    except Exception:
        obs = env.reset()
        info = {}

    # é€‰ä¸€ä¸ªç›®æ ‡ä»£ç†ï¼šé»˜è®¤éšæœºï¼ˆä¹Ÿå¯ä»¥æ”¹ shortest guidanceï¼‰
    target_idx = np.random.randint(env.num_agents)
    teammates = [agent if i == target_idx else AStarAgent() for i in range(env.num_agents)]

    # è·å–ç›®æ ‡/å‚è€ƒæœ€çŸ­é•¿åº¦ï¼ˆå¦‚æœ env æä¾› global_guidanceï¼‰
    try:
        goal = tuple(env.goals[target_idx])
    except Exception:
        goal = None

    state = obs[target_idx]
    try:
        opt_path = [state['global_xy']] + env.global_guidance[target_idx]
        opt_len = max(1, len(opt_path) - 1)
    except Exception:
        opt_len = 1

    # -------- è¶…æ—¶ä¸Šé™ --------
    # åŸºäº episode_idx çš„å›åˆä¸Šé™ï¼ˆä½ åŸé€»è¾‘ï¼‰
    timesteps_per_episode = 50 + 10 * episode_idx
    # å…è®¸ä¼ å…¥æ›´å¼ºçš„æ­¥æ•°ä¸Šé™ï¼ˆä¼˜å…ˆå–æ›´å°çš„é‚£ä¸ªï¼Œä»¥å°½å¿«æ­¢æŸï¼‰
    if isinstance(max_steps_cap, int) and max_steps_cap > 0:
        max_steps_budget = min(timesteps_per_episode, max_steps_cap)
    else:
        max_steps_budget = timesteps_per_episode

    t0 = time.time()
    success = 0
    steps = 0
    timeout_flag = 0

    for t in range(max_steps_budget):
        steps += 1
        if time.time() - t0 > max_episode_seconds:
            timeout_flag = 1
            break

        actions = [ag.act(o) for ag, o in zip(teammates, obs)]
        out = env.step(actions)
        if len(out) == 5:
            obs, reward, terminated, truncated, info = out
        else:
            # å…¼å®¹æ—§å¼ (obs, reward, done, info)
            obs, reward, done, info = out
            terminated, truncated = done, False

        # --- æˆåŠŸåˆ¤å®š #1ï¼šä½ç½®åˆ°è¾¾ç›®æ ‡ ---
        try:
            pos = tuple(obs[target_idx]['global_xy'])
        except Exception:
            pos = None
        if (goal is not None) and (pos is not None) and (pos == goal):
            success = 1
            break

        # --- æˆåŠŸåˆ¤å®š #2ï¼šä» info / terminated / truncated ä¸­è¯»ä¿¡å· ---
        s_from_info = _success_from_info(info, target_idx)
        if s_from_info is True:
            success = 1
            break

        # å¦‚æœ env ææ—©ç»“æŸä¹Ÿè¦é€€å‡ºï¼ˆæŒ‰éœ€å¯æ”¾å®½ï¼‰
        if _bool_from(terminated, target_idx) or _bool_from(truncated, target_idx):
            # è‹¥æ²¡è¯»åˆ°æˆåŠŸä¿¡å·ï¼Œå†å…œåº•ç”¨ä½ç½®
            if success == 0 and (goal is not None) and (pos is not None) and (pos == goal):
                success = 1
            break

        # ç»éªŒå›æ”¾ + åœ¨çº¿å­¦ä¹ 
        agent.store(
            state,
            actions[target_idx],
            reward[target_idx] if isinstance(reward, (list, tuple, np.ndarray)) else reward,
            obs[target_idx],
            bool(_bool_from(terminated, target_idx)),
        )
        state = obs[target_idx]

    return {
        "success": int(success),
        "steps": int(steps),
        "opt_len": float(opt_len),
        "timeout": int(timeout_flag or (steps >= max_steps_budget)),
    }

# ============ ä¸»è®­ç»ƒ/è¯„ä¼°ï¼šæŒ‰å›¾ç»Ÿè®¡æˆåŠŸç‡ ============
def train(
    model: torch.nn.Module,
    maps_cfg: Dict[str, dict],
    episodes_per_map: int = 20,
    batch_size: int = 32,
    replay_buffer_size: int = 1000,
    decay_range: int = 1000,
    lr: float = 1e-3,
    device: str = "cuda",
    log_dir: str = "logs",
    run_dir: Optional[str] = None,
    max_episode_seconds: int = 30,
    max_steps_cap: Optional[int] = None,  # æ–°å¢ï¼šæ­¥æ•°ä¸Šé™ï¼ˆä¾‹å¦‚ 2000ï¼‰ï¼ŒNone åˆ™åªç”¨åŠ¨æ€å›åˆä¸Šé™
) -> pd.DataFrame:

    # è¾“å‡ºç›®å½•
    run_dir = Path(run_dir or (Path(log_dir) / get_timestamp()))
    run_dir.mkdir(parents=True, exist_ok=True)
    writer = SummaryWriter(log_dir=str(run_dir))

    # ä¸ºäº†æ‹¿åŠ¨ä½œç©ºé—´ï¼Œå…ˆç”¨ç¬¬ä¸€å¼ å›¾æ„å»ºä¸€ä¸ª env
    first_name = next(iter(maps_cfg))
    first_env = build_env_from_raw(maps_cfg[first_name])

    agent = DDQNAgent(
        model,
        first_env.get_action_space(),
        lr=lr,
        decay_range=decay_range,
        device=device,
        replay_buffer_size=replay_buffer_size,
    )

    # æ¯å›¾çš„ç»Ÿè®¡å®¹å™¨
    results = []
    global_success_sum = 0
    global_ep_cnt = 0

    # é€å›¾è¯„ä¼°
    for map_name, spec in maps_cfg.items():
        feats = extract_features_from_spec(map_name, spec)
        env = build_env_from_raw(spec)
        pbar = tqdm(range(episodes_per_map), desc=f"Map[{map_name}]", dynamic_ncols=True)

        success_cnt = 0
        timeout_cnt = 0
        for ep in pbar:
            out = run_one_episode(
                env, agent, ep,
                max_episode_seconds=max_episode_seconds,
                max_steps_cap=max_steps_cap
            )
            success_cnt += out["success"]
            timeout_cnt += out["timeout"]

            # åœ¨çº¿æ›´æ–°ï¼ˆå¯é€‰ï¼šæ¯è‹¥å¹²æ­¥å†è®­ç»ƒä¸€æ¬¡ï¼‰
            if len(agent.replay_buffer) >= batch_size:
                _ = agent.retrain(batch_size)

            # TB é€é›†è®°å½•
            writer.add_scalar(f"{map_name}/success", out["success"], ep)
            writer.add_scalar(f"{map_name}/steps", out["steps"], ep)
            writer.add_scalar(f"{map_name}/timeout", out["timeout"], ep)

            pbar.set_postfix(sr=f"{success_cnt/(ep+1):.2f}")

            global_success_sum += out["success"]
            global_ep_cnt += 1
            writer.add_scalar("GLOBAL/success_rate_running", global_success_sum / max(1, global_ep_cnt), global_ep_cnt)

        sr = success_cnt / max(1, episodes_per_map)
        timeout_rate = timeout_cnt / max(1, episodes_per_map)

        row = dict(feats)
        row["success_rate"] = float(sr)
        row["timeout_rate"] = float(timeout_rate)
        results.append(row)

    df = pd.DataFrame(results)

    # ä¿å­˜ CSV
    csv_path = run_dir / "features_vs_success.csv"
    df.to_csv(csv_path, index=False, encoding="utf-8-sig")
    global_sr = df["success_rate"].mean() if len(df) else 0.0
    print(f"ğŸŒ Global Success Rate (mean of per-map SR): {global_sr:.3f}")
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜ï¼š{csv_path}")

    # å¯è§†åŒ–
    try:
        make_feature_success_plots(run_dir, df)
        print(f"ğŸ“Š å¯è§†åŒ–å·²è¾“å‡ºåˆ°ï¼š{run_dir}")
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å¤±è´¥ï¼š{e}")

    writer.close()
    return df

# ============ å¯è§†åŒ–ï¼šFeatures vs Success ============
def make_feature_success_plots(out_dir: Union[str, Path], df: pd.DataFrame):
    """
    ç”Ÿæˆï¼š
    - success_rate by map çš„æŸ±çŠ¶å›¾
    - æ¯ä¸ªç‰¹å¾ vs success_rate çš„æ•£ç‚¹å›¾ï¼ˆè‡ªåŠ¨æŒ‘æ•°å€¼åˆ—ï¼‰
    - ç‰¹å¾+æˆåŠŸç‡çš„ç›¸å…³æ€§çƒ­å›¾
    """
    out_dir = Path(out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    # 1) æ¯å›¾æˆåŠŸç‡æŸ±çŠ¶å›¾
    try:
        df_sorted = df.sort_values("success_rate")
        plt.figure(figsize=(max(8, 0.35*len(df_sorted)), 5))
        plt.bar(df_sorted["map_name"].astype(str), df_sorted["success_rate"].values)
        plt.xticks(rotation=60, ha="right")
        plt.ylabel("Success Rate")
        plt.title("Success Rate by Map")
        plt.tight_layout()
        plt.savefig(out_dir / "sr_by_map.png", dpi=150)
        plt.close()
    except Exception as e:
        print(f"[Plot] sr_by_map.png å¤±è´¥: {e}")

    # 2) æ¯ä¸ªæ•°å€¼ç‰¹å¾ vs success_rate æ•£ç‚¹å›¾
    numeric_cols = []
    for c in df.columns:
        if c in ["map_name", "success_rate"]:
            continue
        try:
            if pd.api.types.is_numeric_dtype(df[c]):
                numeric_cols.append(c)
        except Exception:
            pass

    for c in numeric_cols:
        try:
            d = df.dropna(subset=[c, "success_rate"])
            if len(d) == 0:
                continue
            plt.figure(figsize=(6, 4))
            plt.scatter(d[c].values, d["success_rate"].values, s=18)
            plt.xlabel(c)
            plt.ylabel("Success Rate")
            plt.title(f"Success Rate vs {c}")
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(out_dir / f"success_vs_{c}.png", dpi=150)
            plt.close()
        except Exception as e:
            print(f"[Plot] success_vs_{c}.png å¤±è´¥: {e}")

    # 3) ç›¸å…³æ€§çƒ­å›¾ï¼ˆç”¨ matplotlibï¼Œé¿å… seaborn ä¾èµ–ï¼‰
    try:
        corr_cols = ["success_rate"] + numeric_cols
        dnum = df[corr_cols].copy()
        dnum = dnum.apply(pd.to_numeric, errors="coerce")
        cm = dnum.corr().values
        labels = dnum.columns.tolist()

        plt.figure(figsize=(1.2*len(labels), 1.0*len(labels)))
        im = plt.imshow(cm, cmap="coolwarm", vmin=-1, vmax=1)
        plt.colorbar(im, fraction=0.046, pad=0.4)
        plt.xticks(range(len(labels)), labels, rotation=60, ha="right")
        plt.yticks(range(len(labels)), labels)
        plt.title("Correlation (numeric features & success_rate)")
        # åœ¨æ ¼å­é‡Œæ ‡æ³¨ç›¸å…³ç³»æ•°
        for i in range(len(labels)):
            for j in range(len(labels)):
                plt.text(j, i, f"{cm[i,j]:.2f}", ha="center", va="center", fontsize=8)
        plt.tight_layout()
        plt.savefig(out_dir / "correlation_heatmap.png", dpi=150)
        plt.close()
    except Exception as e:
        print(f"[Plot] correlation_heatmap.png å¤±è´¥: {e}")

# ============ å…¥å£ ============
if __name__ == "__main__":
    os.makedirs('logs', exist_ok=True)
    os.makedirs('models', exist_ok=True)

    # è¯»å–ä½ çš„ YAMLï¼ˆä½¿ç”¨ä½ ç»™çš„è·¯å¾„ï¼‰
    MAP_SETTINGS_PATH = r'C:/Users/MSc_SEIoT_1/MAPF_G2RL-main - train/g2rl/map_settings_generated_new.yaml'
    with open(MAP_SETTINGS_PATH, "r", encoding="utf-8") as f:
        base_map_settings = yaml.safe_load(f)

    # é¡¶å±‚æ˜¯ list â†’ {name: spec}
    if isinstance(base_map_settings, list):
        base_map_settings = {
            (m.get("name") or f"map_{i}"): m
            for i, m in enumerate(base_map_settings)
        }

    # æ¨¡å‹ & è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CRNNModel().to(device)

    # å¯¹æ¯å¼ å›¾è·‘å›ºå®šè‹¥å¹²é›†ï¼Œç»Ÿè®¡ features vs success
    df = train(
        model=model,
        maps_cfg=base_map_settings,
        episodes_per_map=300,                 # â¬…ï¸ æ¯å¼ å›¾è¯„ä¼°å¤šå°‘é›†ï¼ˆå¯è°ƒï¼‰
        batch_size=32,
        replay_buffer_size=1000,
        decay_range=1000,
        lr=1e-3,
        device=device,
        log_dir='logs',
        run_dir="C:/Users/MSc_SEIoT_1/MAPF_G2RL-main - train/features_success_run_1",
        max_episode_seconds=30,               # â¬…ï¸ å¢™é’Ÿè¶…æ—¶ï¼ˆç§’ï¼‰
        max_steps_cap=2000,                   # â¬…ï¸ æ­¥æ•°ä¸Šé™ï¼ˆNone è¡¨ç¤ºä¸ç”¨ï¼‰
    )

    # å¯é€‰ï¼šä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), 'models/best_model_1.pt')
    print('âœ… æ¨¡å‹å·²ä¿å­˜åˆ° models/best_model.pt')


