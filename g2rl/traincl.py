# traincl.py  â€” cleaned & fixed
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
from typing import List, Dict, Optional, Union
from collections import deque
import os
import sys
import time
import csv
import random
import math
import inspect
# æ”¾åœ¨æ–‡ä»¶é¡¶éƒ¨å…¶å®ƒ import ä¹‹å
import matplotlib
import matplotlib.pyplot as plt

import numpy as np
import pandas as pd
import torch
from torch.utils.tensorboard import SummaryWriter
import yaml

from pogema import AStarAgent

# --- é¡¹ç›®æ ¹è·¯å¾„ç¡®ä¿åœ¨ sys.path ä¸­ ---
project_root = r"C:/Users/MSc_SEIoT_1/MAPF_G2RL-main"
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# --- ä½ é¡¹ç›®çš„æ¨¡å— ---
from g2rl.environment import G2RLEnv
from g2rl.agent import DDQNAgent
from g2rl.network import CRNNModel
from g2rl import moving_cost, detour_percentage

# å¦‚æœä»éœ€åŸ Schedulerï¼Œå¯ä¿ç•™ï¼›å½“å‰è„šæœ¬ä½¿ç”¨ ComplexityScheduler
# from g2rl.curriculum import CurriculumScheduler

# ============ å®‰å…¨æ„é€ å™¨ï¼šè¿‡æ»¤ __init__ ä¸è®¤è¯†çš„é”® ============
def build_env_from_raw(raw_cfg: dict) -> G2RLEnv:
    """
    åªæŠŠ G2RLEnv.__init__ è®¤è¯†çš„å‚æ•°ä¼ è¿›å»ï¼›
    å…¶ä»–ï¼ˆgrid/starts/goals ç­‰ï¼‰åœ¨å®ä¾‹åŒ–åä½œä¸ºå±æ€§æŒ‚è½½ã€‚
    """
    sig = inspect.signature(G2RLEnv.__init__)
    allowed = {
        p.name for p in sig.parameters.values()
        if p.kind in (inspect.Parameter.POSITIONAL_OR_KEYWORD, inspect.Parameter.KEYWORD_ONLY)
    }
    allowed.discard("self")

    # å¦‚æœ‰å‘½åä¸ä¸€è‡´ï¼Œåœ¨è¿™é‡Œåšé‡å‘½åæ˜ å°„ï¼ˆæŒ‰ä½ é¡¹ç›®éœ€è¦è¡¥ï¼‰
    rename = {
        # 'size': 'map_size',
        # 'num_agents': 'n_agents',
    }

    ctor_cfg = {}
    for k, v in raw_cfg.items():
        kk = rename.get(k, k)
        if kk in allowed:
            ctor_cfg[kk] = v

    env = G2RLEnv(**ctor_cfg)

    # æŠŠé¢å¤–ä¿¡æ¯æŒ‚åˆ° env ä¸Šï¼ˆä¸è¿› __init__ï¼‰
    if "grid" in raw_cfg:
        try:
            env.grid = (np.array(raw_cfg["grid"]) > 0).astype(np.uint8)
        except Exception:
            env.grid = None
    if "starts" in raw_cfg:
        env.starts = raw_cfg["starts"]
    if "goals" in raw_cfg:
        env.goals = raw_cfg["goals"]

    return env

# ============ Complexity-based Curriculum Scheduler ============
from g2rl.complexity_module import compute_map_complexity

INTERCEPT = 0.848
WEIGHTS = {
    'Size': 0.021,
    'Agents': -0.010,
    'Density': 0.077,
    'Density_actual': 0.132,
    'LDD': 0.027,
    'BN': -0.128,
    'MC': 0.039,
    'DLR': 0.002,
}
FEATURE_MEAN_STD = None  # è‹¥è®­ç»ƒæ—¶åšè¿‡æ ‡å‡†åŒ–ï¼ŒæŒ‰ {'Size':(mu, sigma), ...} ä¼ å…¥


def _build_stages_by_quantile_df(df: pd.DataFrame, n_stages: int = 5, min_per_stage: int = 5):
    if len(df) == 0:
        raise ValueError("æ²¡æœ‰å¯ç”¨åœ°å›¾ç”¨äº complexity è¯¾ç¨‹ã€‚")
    qs = np.linspace(0, 1, n_stages + 1)
    edges = np.quantile(df["complexity"].values, qs)
    stages = []
    for i in range(n_stages):
        lo, hi = float(edges[i]), float(edges[i+1]) + 1e-12
        sub = df[(df["complexity"] >= lo) & (df["complexity"] < hi)]
        if len(sub) < min_per_stage:
            need = min_per_stage - len(sub)
            center = (lo + hi) / 2.0
            extra = df.iloc[(df["complexity"] - center).abs().argsort()[:need]]
            sub = pd.concat([sub, extra]).drop_duplicates(subset=["name"])
        stages.append({
            "stage": i,
            "cpx_min": lo,
            "cpx_max": hi,
            "items": sub.to_dict("records"),  # æ¯æ¡å« name/spec/complexity
        })
    return stages
def _compute_complexities_for_settings(base_map_settings: Dict[str, dict],
                                       size_mode: str = "max") -> pd.DataFrame:
    rows = []
    for name, spec in base_map_settings.items():
        try:
            cpx, used, raw = compute_map_complexity(
                spec, intercept=INTERCEPT, weights=WEIGHTS,
                feature_mean_std=FEATURE_MEAN_STD, size_mode=size_mode
            )
            # â˜… åœ¨ spec é‡Œå¡å…¥ complexity
            spec_with_cpx = dict(spec)
            spec_with_cpx["complexity"] = float(cpx)

            rows.append({
                "name": name,
                "complexity": float(cpx),
                "spec": spec_with_cpx,   # â˜… ç”¨å¸¦ complexity çš„ spec
            })
        except Exception as e:
            rows.append({"name": name, "error": str(e), "spec": spec})
    df = pd.DataFrame(rows)
    if "error" in df.columns:
        df = df[df["error"].isna()]
    return df.sort_values("complexity").reset_index(drop=True)

def _rolling_mean(x, w=50):
    if len(x) == 0:
        return np.array([])
    w = max(1, int(w))
    c = np.cumsum(np.insert(x, 0, 0))
    # ç®€å•æ»šåŠ¨å¹³å‡ï¼›å¯¹å‰ w-1 é¡¹ç”¨æ›´çŸ­çª—å£é¿å…ç©ºç¼º
    rm = (c[w:] - c[:-w]) / float(w)
    head = [np.mean(x[:i+1]) for i in range(min(w-1, len(x)))]
    return np.array(head + rm.tolist())

def make_training_plots(out_dir: str, df: pd.DataFrame, *, win: int = 50):
    os.makedirs(out_dir, exist_ok=True)

    # -------- 1) Success & Rolling SR vs Episode --------
    plt.figure(figsize=(10, 5))
    ep = df["episode"].values
    succ = df["success"].values.astype(float)
    plt.plot(ep, succ, label="Success (0/1)", linewidth=1)
    rm = _rolling_mean(succ, w=win)
    if len(rm) > 0:
        plt.plot(ep[:len(rm)], rm, linewidth=2, label=f"Rolling SR (w={win})")
    plt.xlabel("Episode"); plt.ylabel("Success / SR")
    plt.title("Success & Rolling Success-Rate")
    plt.grid(True, alpha=0.3); plt.legend()
    plt.tight_layout(); plt.savefig(os.path.join(out_dir, "sr_curve.png"), dpi=150); plt.close()

    # -------- 2) Loss & Epsilon vs Episode --------
    if "avg_loss" in df.columns or "avg_epsilon" in df.columns:
        plt.figure(figsize=(10, 5))
        if "avg_loss" in df.columns:
            plt.plot(df["episode"], df["avg_loss"], label="Avg Loss")
        if "avg_epsilon" in df.columns:
            plt.plot(df["episode"], df["avg_epsilon"], label="Avg Epsilon")
        plt.xlabel("Episode"); plt.title("Loss & Epsilon")
        plt.grid(True, alpha=0.3); plt.legend()
        plt.tight_layout(); plt.savefig(os.path.join(out_dir, "loss_epsilon.png"), dpi=150); plt.close()

    # -------- 3) Steps / MovingCost / Detour vs Episode --------
    plt.figure(figsize=(12, 6))
    ax1 = plt.subplot(3,1,1); ax1.plot(df["episode"], df["steps"]); ax1.set_title("Steps per Episode"); ax1.grid(True, alpha=0.3)
    ax2 = plt.subplot(3,1,2); 
    if "moving_cost" in df.columns:
        ax2.plot(df["episode"], df["moving_cost"]); ax2.set_title("Moving Cost (success only may be non-NaN)"); ax2.grid(True, alpha=0.3)
    ax3 = plt.subplot(3,1,3);
    if "detour_pct" in df.columns:
        ax3.plot(df["episode"], df["detour_pct"]); ax3.set_title("Detour Percentage (success only may be non-NaN)"); ax3.grid(True, alpha=0.3)
    plt.tight_layout(); plt.savefig(os.path.join(out_dir, "steps_moving_detour.png"), dpi=150); plt.close()

    # -------- 4) Complexity vs Success (per-episode scatter) --------
    if "complexity" in df.columns and df["complexity"].notna().any():
        plt.figure(figsize=(8,5))
        plt.scatter(df["complexity"], df["success"], s=18)
        plt.xlabel("Complexity"); plt.ylabel("Success (0/1)")
        plt.title("Episode Success vs Complexity")
        plt.grid(True, alpha=0.3)
        plt.tight_layout(); plt.savefig(os.path.join(out_dir, "success_vs_complexity_scatter.png"), dpi=150); plt.close()

    # -------- 5) Success by Complexity Bucket --------
    if "complexity" in df.columns and df["complexity"].notna().any():
        d = df.dropna(subset=["complexity"]).copy()
        if len(d) > 3:
            edges = np.quantile(d["complexity"].values, np.linspace(0, 1, 6))  # 5 æ¡¶
            d["bucket"] = pd.cut(d["complexity"], bins=edges, include_lowest=True, right=False)
            sr_by_bucket = d.groupby("bucket")["success"].mean()
            plt.figure(figsize=(8,5)); sr_by_bucket.plot(kind="bar")
            plt.ylabel("Mean Success Rate"); plt.title("Success Rate by Complexity Bucket (episodes)")
            plt.tight_layout(); plt.savefig(os.path.join(out_dir, "sr_by_bucket.png"), dpi=150); plt.close()

    # -------- 6) Per-Stage SR --------
    if "stage" in df.columns:
        st = df.groupby("stage")["success"].mean()
        plt.figure(figsize=(8,5)); st.plot(kind="bar")
        plt.ylabel("Mean Success Rate"); plt.title("Success Rate by Stage (episodes)")
        plt.tight_layout(); plt.savefig(os.path.join(out_dir, "sr_by_stage.png"), dpi=150); plt.close()


class ComplexityScheduler:
    """
    åˆ†é˜¶æ®µè¯¾ç¨‹ï¼š
      - æ¯ä¸ªé˜¶æ®µæŒæœ‰ä¸€ç»„ mapsï¼ˆç”± complexity åˆ†ä½åˆ‡åˆ†ï¼‰
      - æ¯é˜¶æ®µè‡³å°‘è·‘ min_episodes_per_stage é›†
      - è¾¾åˆ°é˜ˆå€¼ï¼ˆæ»‘çª—æˆ–é˜¶æ®µç´¯è®¡ï¼‰åæ™‹çº§
    """

    
    def __init__(self,
                 base_map_settings: Dict[str, dict],
                 n_stages: int = 5,
                 min_per_stage: int = 5,
                 # åˆ¤å®šç›¸å…³
                 min_episodes_per_stage: int =200 ,   # æ¯é˜¶æ®µè‡³å°‘è®­ç»ƒè¿™ä¹ˆå¤š episode
                 threshold: float = 0.70,             # æˆåŠŸç‡é˜ˆå€¼
                 window_size: int = 100,              # æ»‘çª—å¤§å°
                 use_window_sr: bool = True,          # True=ç”¨æ»‘çª—SRï¼›False=ç”¨é˜¶æ®µç´¯è®¡SR
                 # å…¶å®ƒ
                 shuffle_each_stage: bool = True,
                 seed: int = 0,
                 size_mode: str = "max"):
        self.min_episodes_per_stage = int(min_episodes_per_stage)
        self.threshold = float(threshold)
        self.window_size = int(window_size)
        self.use_window_sr = bool(use_window_sr)

        self._rng = random.Random(seed)
        df = _compute_complexities_for_settings(base_map_settings, size_mode=size_mode)
        stages = _build_stages_by_quantile_df(df, n_stages=n_stages, min_per_stage=min_per_stage)

        self._stage_items = []
        self._stage_edges = []
        for st in stages:
            items = list(st["items"])
            if shuffle_each_stage:
                self._rng.shuffle(items)
            self._stage_items.append(items)
            self._stage_edges.append((st["cpx_min"], st["cpx_max"]))

        self.current_stage = 0
        self.max_stage = len(self._stage_items) - 1

        # è½®è½¬é‡‡æ ·ç´¢å¼•
        self._idx_in_stage = 0
        # ç»Ÿè®¡
        self._win = deque(maxlen=self.window_size)  # æ»‘çª—
        self._ep_in_stage = 0                       # é˜¶æ®µ episode æ•°
        self._succ_in_stage = 0                     # é˜¶æ®µæˆåŠŸ episode æ•°
    
    

    # ============ å–å›¾ ============
    def get_updated_map_settings(self) -> Dict[str, dict]:
        if self.current_stage > self.max_stage:
            return {}
        items = self._stage_items[self.current_stage]
        if not items:
            raise RuntimeError(f"Stage {self.current_stage} æ²¡æœ‰åœ°å›¾ã€‚")
        item = items[self._idx_in_stage]
        self._idx_in_stage = (self._idx_in_stage + 1) % len(items)
        # spec ä¸­ä¿ç•™ complexityï¼Œæ–¹ä¾¿è®­ç»ƒä¾§æ‰“å°
        return {item["name"]: item["spec"]}

    # ============ ç»Ÿè®¡ & åˆ¤å®š ============
    def add_episode_result(self, success: int):
        s = 1 if success else 0
        self._win.append(s)
        self._ep_in_stage += 1
        self._succ_in_stage += s

    def window_sr(self) -> float:
        return float(sum(self._win) / len(self._win)) if len(self._win) else 0.0

    def stage_sr(self) -> float:
        return float(self._succ_in_stage / max(1, self._ep_in_stage))

    def should_advance(self) -> bool:
        """æ˜¯å¦æ»¡è¶³æ™‹çº§æ¡ä»¶ï¼šè·‘æ»¡æœ€å°‘é›†æ•° ä¸” æˆåŠŸç‡è¾¾æ ‡"""
        if self._ep_in_stage < self.min_episodes_per_stage:
            return False
        sr = self.window_sr() if self.use_window_sr else self.stage_sr()
        return sr >= self.threshold

    # ============ é˜¶æ®µåˆ‡æ¢ ============
    def advance(self, pbar=None):
        if pbar:
            lo, hi = self._stage_edges[self.current_stage]
            pbar.write(
                f"âœ… é€šè¿‡ Stage {self.current_stage} | "
                f"SR(win)={self.window_sr():.2f} / SR(stage)={self.stage_sr():.2f} | "
                f"åŒºé—´[{lo:.4f}, {hi:.4f}] â†’ Stage {self.current_stage + 1}"
            )
        self.current_stage += 1
        self._reset_stage_stats()


    def repeat_stage(self, pbar=None):
        if pbar:
            pbar.write(f"ğŸ” æœªè¾¾æ ‡ï¼Œé‡å¤ Stage {self.current_stage}ï¼ˆå·²è®­ç»ƒ {self._ep_in_stage} epï¼ŒSR={self.stage_sr():.2f}ï¼‰")
        self._reset_stage_stats()

    def _reset_stage_stats(self):
        self._idx_in_stage = 0
        self._win.clear()
        self._ep_in_stage = 0
        self._succ_in_stage = 0

    def is_done(self) -> bool:
        return self.current_stage > self.max_stage


# ================== è®­ç»ƒç›¸å…³ ==================
def get_timestamp() -> str:
    return datetime.now().strftime('%H-%M-%d-%m-%Y')

def get_normalized_probs(x: Union[List[float], None], size: int) -> np.ndarray:
    x = [1] * size if x is None else x + [0] * (size - len(x))
    e_x = np.exp(x - np.max(x))
    return e_x / e_x.sum(axis=0)

def train(
        model: torch.nn.Module,
        map_settings: Dict[str, dict],
        map_probs: Union[List[float], None],
        num_episodes: int = 300,
        batch_size: int = 32,
        decay_range: int = 1000,
        log_dir: str = 'logs',
        lr: float = 0.001,
        replay_buffer_size: int = 1000,
        device: str = 'cuda',
        scheduler: Optional[ComplexityScheduler] = None,
        max_episode_seconds: int = 30,
        run_dir: Optional[str] = None
    ) -> DDQNAgent:

    # === ç»Ÿä¸€ç¡®å®šè¾“å‡ºç›®å½• ===
    if run_dir is None:
        from datetime import datetime
        timestamp = datetime.now().strftime('%H-%M-%d-%m-%Y')
        run_dir = Path(log_dir) / timestamp
    else:
        run_dir = Path(run_dir)

    run_dir.mkdir(parents=True, exist_ok=True)

    # TensorBoard å†™æ—¥å¿—åˆ° run_dir
    writer = SummaryWriter(log_dir=run_dir)

    training_logs = []



    # åˆå§‹åŒ–ç¬¬ä¸€ä¸ª env è·å–åŠ¨ä½œç©ºé—´
    first_name = next(iter(map_settings))
    first_env = build_env_from_raw(map_settings[first_name])
    agent = DDQNAgent(
        model,
        first_env.get_action_space(),
        lr=lr,
        decay_range=decay_range,
        device=device,
        replay_buffer_size=replay_buffer_size,
    )

    pbar = tqdm(range(num_episodes), desc='Episodes', dynamic_ncols=True)

    episode = 0
    success_count_total = 0
    stage_success_count = 0
    stage_episode_count = 0
    stage_threshold = getattr(scheduler, "threshold", 0.8) if scheduler else 0.8

    while (scheduler is None) or (scheduler.current_stage <= scheduler.max_stage):
        if episode >= num_episodes:
            break

        # 1) é˜¶æ®µåœ°å›¾
        cur_map_cfg = scheduler.get_updated_map_settings() if scheduler else map_settings
        map_type, cfg = next(iter(cur_map_cfg.items()))
        env = build_env_from_raw(cfg)

        cpx_val = cfg.get("complexity", None)  # â˜… ç›´æ¥ä» cfg é‡Œå–
        stage_id = scheduler.current_stage if scheduler else '-'
        if cpx_val is not None:
            pbar.write(f"ğŸŸ¢ ä½¿ç”¨åœ°å›¾ï¼š{map_type} | Stage {stage_id} | Agents={env.num_agents} | Complexity={cpx_val:.3f}")
        else:
            pbar.write(f"ğŸŸ¢ ä½¿ç”¨åœ°å›¾ï¼š{map_type} | Stage {stage_id} | Agents={env.num_agents}")



        # 2) reset
        obs, info = env.reset()
        target_idx = np.random.randint(env.num_agents)
        agents = [agent if i == target_idx else AStarAgent() for i in range(env.num_agents)]
        goal = tuple(env.goals[target_idx])
        state = obs[target_idx]
        opt_path = [state['global_xy']] + env.global_guidance[target_idx]

        success_flag = False
        retrain_count = 0
        scalars = {
            'Reward': 0.0,
            'Moving Cost': 0.0,
            'Detour Percentage': 0.0,
            'Average Loss': 0.0,
            'Average Epsilon': 0.0,
            'Success': 0
        }

        # 3) ä¸€é›†
        timesteps_per_episode = 50 + 10 * episode
        episode_start_time = time.time()

        for t in range(timesteps_per_episode):
            if time.time() - episode_start_time > max_episode_seconds:
                pbar.write(f"â° Episode {episode} è¶…æ—¶ï¼ˆ>{max_episode_seconds}sï¼‰ï¼Œå¼ºåˆ¶ç»ˆæ­¢")
                break

            actions = [ag.act(o) for ag, o in zip(agents, obs)]
            obs, reward, terminated, truncated, info = env.step(actions)

            agent_pos = tuple(obs[target_idx]['global_xy'])
            done = (agent_pos == goal)
            terminated[target_idx] = done

            if done:
                success_flag = True
                scalars['Success'] = 1
                scalars['Moving Cost'] = moving_cost(t + 1, opt_path[0], opt_path[-1])
                scalars['Detour Percentage'] = detour_percentage(t + 1, len(opt_path) - 1)
                break

            # ç»éªŒ
            agent.store(
                state,
                actions[target_idx],
                reward[target_idx],
                obs[target_idx],
                terminated[target_idx],
            )
            state = obs[target_idx]
            scalars['Reward'] += float(reward[target_idx])

            if len(agent.replay_buffer) >= batch_size:
                retrain_count += 1
                scalars['Average Loss'] += float(agent.retrain(batch_size))
                scalars['Average Epsilon'] += float(agent.epsilon)

        if retrain_count > 0:
            scalars['Average Loss'] /= retrain_count
            scalars['Average Epsilon'] /= retrain_count

        if success_flag:
            success_count_total += 1
            stage_success_count += 1
        scalars['Success'] = 1 if success_flag else 0
                # ç»Ÿè®¡æ­¥æ•°
        steps_this = t + 1 if 't' in locals() else 0

        # è®°å½•ä¸€æ¡ episodio æ—¥å¿—
        training_logs.append({
            "episode": episode,
            "stage": (scheduler.current_stage if scheduler else -1),
            "map": map_type,
            "agents": env.num_agents,
            "complexity": (cpx_val if cpx_val is not None else np.nan),
            "success": int(scalars['Success']),
            "reward": float(scalars['Reward']),
            "steps": int(steps_this),
            "avg_loss": float(scalars['Average Loss']),
            "avg_epsilon": float(scalars['Average Epsilon']),
            "moving_cost": float(scalars.get('Moving Cost', np.nan)),
            "detour_pct": float(scalars.get('Detour Percentage', np.nan)),
        })

        stage_episode_count += 1
        episode += 1
        pbar.update(1)

        for name, value in scalars.items():
            writer.add_scalar(name, value, episode)

        pbar.set_postfix(
            Stage=(scheduler.current_stage if scheduler else "-"),
            SR_total=f"{success_count_total / max(1, episode):.2f}",
            R=f"{scalars['Reward']:.2f}",
        )

        # 5) è¯¾ç¨‹é€»è¾‘
        # 5) è¯¾ç¨‹é€»è¾‘ï¼šè¾¾æ ‡æ™‹çº§ï¼ˆè·‘æ»¡æœ€å°‘é›†æ•° + æˆåŠŸç‡è¾¾æ ‡ï¼‰
        if scheduler is not None:
            scheduler.add_episode_result(scalars['Success'])

            if scheduler.should_advance():
                scheduler.advance(pbar)
                # è¿›å…¥ä¸‹ä¸€é˜¶æ®µå°±ç»§ç»­å¾ªç¯ï¼ˆä¼šè‡ªåŠ¨æŠ½å–ä¸‹ä¸€é˜¶æ®µçš„æ›´éš¾åœ°å›¾ï¼‰
                if scheduler.is_done():
                    break
                continue
            else:
                # æ²¡è¾¾æ ‡ä½†è¿˜æ²¡æ»¡æœ€å°‘é›†æ•°ï¼šç»§ç»­è®­ç»ƒæœ¬é˜¶æ®µ
                # å¦‚æœä½ æƒ³åŠ â€œæ»¡æœ€å°‘é›†æ•°ä½†è¿˜æœªè¾¾æ ‡â†’å¼ºåˆ¶é‡ç½®å¹¶é‡å¤æœ¬é˜¶æ®µâ€ï¼Œå¯åŠ ï¼š
                if scheduler._ep_in_stage >= scheduler.min_episodes_per_stage:
                    scheduler.repeat_stage(pbar)
                # ç„¶åç»§ç»­è¯¥é˜¶æ®µè®­ç»ƒ


        #     # å¯é€‰ï¼šæ»‘çª—å¿«é€Ÿé€šé“
        # elif scheduler.ready_to_advance():
        #         scheduler.advance(pbar)
        #         stage_success_count = 0
        #         stage_episode_count = 0
        #         if scheduler.is_done():
        #             break

    final_sr = success_count_total / max(1, episode)
    agent.final_success_rate = float(final_sr)
    print(f"[train] final_sr(global) = {success_count_total}/{episode} = {agent.final_success_rate:.6f}")
    
        # === ä¿å­˜ CSV & å¯è§†åŒ– ===
    df_train = pd.DataFrame(training_logs)
    csv_path = run_dir / "episodes.csv"
    df_train.to_csv(csv_path, index=False, encoding="utf-8-sig")
    print(f"ğŸ“ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜ï¼š{csv_path}")

    try:
        make_training_plots(str(run_dir), df_train, win=50)
        print(f"ğŸ“Š è®­ç»ƒå¯è§†åŒ–å·²ä¿å­˜åˆ°ï¼š{run_dir}")
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å¤±è´¥ï¼š{e}")


    writer.close()
    return agent

# ================== å…¥å£ ==================
if __name__ == '__main__':
    os.makedirs('logs', exist_ok=True)
    os.makedirs('models', exist_ok=True)

    MAP_SETTINGS_PATH = 'C:/Users/MSc_SEIoT_1/MAPF_G2RL-main/g2rl/map_settings_generated.yaml'
    with open(MAP_SETTINGS_PATH, "r", encoding="utf-8") as f:
        base_map_settings = yaml.safe_load(f)

    if isinstance(base_map_settings, list):
        base_map_settings = { (m.get("name") or f"map_{i}"): m for i, m in enumerate(base_map_settings) }

    scheduler = ComplexityScheduler(
        base_map_settings=base_map_settings,
        n_stages=5,
        min_per_stage=10,
        min_episodes_per_stage=100,
        threshold=0.70,
        window_size=100,
        shuffle_each_stage=True,
        seed=0,
        size_mode="max",
    )

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CRNNModel().to(device)

    trained_agent = train(
        model=model,
        scheduler=scheduler,
        map_settings=scheduler.get_updated_map_settings(),  # åˆå§‹ä¸€å¼ ï¼›train å†…æ¯é›†ä¼šå†å–
        map_probs=None,
        num_episodes=300,
        batch_size=32,
        replay_buffer_size=500,
        decay_range=10_000,
        log_dir='logs',
        device=device,
        run_dir="C:/Users/MSc_SEIoT_1/MAPF_G2RL-main/pics/traincl"
    )

    torch.save(model.state_dict(), 'models/model1.pt')
    print('âœ… æ¨¡å‹å·²ä¿å­˜åˆ° models/model1.pt')
